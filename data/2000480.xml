<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[SHF: Small: Collaborative Research: Software Hardware Architecture Co-design for Low-power Heterogeneous Edge Devices]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>179999.00</AwardTotalIntnAmount>
<AwardAmount>179999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Danella Zhao</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The advancement of deep learning techniques, a sub-field of machine learning, is profoundly changing the field of mobile edge computing, thanks to recent research demonstrating that deep learning methods provide significant performance gains. However, the requirement of heavy computations and resources prevent deep learning methods from being widely deployed in mobile edge devices, such as smartphones and Internet of Things (IoT) devices. A significant advantage of enabling deep learning methods in mobile edge devices is that it can drastically reduce the response delay and energy consumption of mobile applications because the computations are executed locally. By removing the barrier that keeps deep learning techniques away from pervasive low-power mobile edge computing devices, this research enables high-accuracy, low-latency applications in future mobile edge computing. In particular, this research systematically investigates the fundamental and challenging issues targeting to significantly reduce the cost of deep learning inference process in mobile edge devices with guaranteed performance. The success of this project could significantly benefit the entire spectrum of deep learning across various research domains, including computer architecture, mobile sensing, cyber security, and human-computer interaction research areas. This project also aims to develop new curricula and encourage the participation of female engineering students. &lt;br/&gt;&lt;br/&gt;The primary goal of this research is to build a software accelerator that enables the broad deployment of heavy-cost deep learning models into resource-constrained, heterogeneous mobile edge devices (e.g., low-cost sensing platforms and IoT devices). The basic idea is to develop deep-learning resource management algorithms that can adjust structures of different deep learning models according to hardware constraints of heterogeneous edge devices. More specifically, this research analyzes distinct deep learning behaviors on mobile edge devices and designs different strategies to improve the efficiency of multiple deep-learning-based inference models. Furthermore, this research develops algorithms that can adjust the complexity of different deep learning models to reduce their energy and memory consumption on mobile edge devices. In addition, this project designs power-centric resource reallocation algorithms to verify and deploy the mobile-friendly deep learning models.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>10/22/2019</MinAmdLetterDate>
<MaxAmdLetterDate>10/22/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2000480</AwardID>
<Investigator>
<FirstName>Yan</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yan Wang</PI_FULL_NAME>
<EmailAddress><![CDATA[y.wang@temple.edu]]></EmailAddress>
<NSF_ID>000702932</NSF_ID>
<StartDate>10/22/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Temple University]]></Name>
<CityName>PHILADELPHIA</CityName>
<ZipCode>191226104</ZipCode>
<PhoneNumber>2157077547</PhoneNumber>
<StreetAddress><![CDATA[1805 N BROAD ST]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA02</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>QD4MGHFDJKU1</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>TEMPLE UNIVERSITY-OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>QD4MGHFDJKU1</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Temple University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>191226003</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>779800</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01001920DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2019~179999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project explored designing a software accelerator that enables the broad deployment of heavy-cost deep learning models into resource-constrained, heterogeneous mobile edge devices (e.g., low-cost sensing platforms and IoT devices). More specifically, this project analyzed distinct deep-learning behaviors on mobile edge devices and designed different strategies to improve the efficiency of multiple deep-learning-based inference models. Furthermore, innovative compression algorithms are developed to adjust the complexity of different deep learning models and reduce their energy and memory consumption on mobile edge devices. Finally, this project developed power-centric reallocation algorithms to verify and deploy mobile-friendly deep learning models in multiple application domains. Particularly, we accomplished the following aspects. (1) Global Mixture Pruning for Further Flops Compression via Neuron Bond. (2) Solving the WiFi Sensing Dilemma in Reality Leveraging Conformal Prediction. (3) Secure and Efficient Mobile DNN Using Trusted Execution Environments.&nbsp;</p> <p>(1) Global Mixture Pruning for Further Flops Compression via Neuron Bond. Neuron network pruning is effective in compressing pre-trained CNNs for their deployment on low-end edge devices. However, only some works have focused on reducing the computational cost of pruning and inference. We found that existing pruning methods usually remove parameters without fine-grained impact analysis, making it hard to achieve an optimal solution. We developed a global mixture pruning mechanism to effectively reduce the computational cost of CNNs while maintaining a high weight compression ratio and model accuracy. We proposed removing neuron bonds in the convolution layer and fully connected layers to skip the corresponding computation for generating each pixel of the output map. We also designed an influence factor to analyze the importance of neuron bonds and weights in a fine-grained way so that our approach could significantly reduce the pruning iterations by only performing a one-shot pruning when the total number of unimportant parameters reaches the compress ratio. Therefore, our approach required fewer retraining iterations to recover the accuracy of the network.</p> <p>(2) Solving the WiFi Sensing Dilemma in Reality Leveraging Conformal Prediction. With the broad deployment of smart environments and IoT devices, WiFi sensing has demonstrated its great convenience and contactless sensing capabilities in supporting various applications. However, designing a ubiquitous WiFi sensing system for heterogeneous scenarios in practice is still a big dilemma, as the system performs poorly when the testing data is significantly different from the training data caused by domain variations. To address this dilemma, we conducted a comprehensive study of the domain variation problems in various WiFi sensing applications and developed a holistic WiFi sensing framework using conformal prediction that can ensure high prediction accuracy when facing different domain variations in reality. Novel kernel density-based nonconformity measure and cross-domain conformal prediction were developed to achieve more accurately determine the most possible class(es) of the input data. The proposed framework is reliazed to study its effectiveness in typical WiFi sensing applications (i.e., user identification, activity classification, and gesture recognition).</p> <p>(3) Secure and Efficient Mobile DNN Using Trusted Execution Environments. As mobile applications increasingly rely on deep neural networks (DNNs) for their powerful inference capabilities, there is a growing need for secure DNN execution on mobile devices. Towards this end, hardware-based trusted execution environments on mobile devices (mobile TEEs) such as ARM TrustZone are being utilized for secure DNN execution. This project developed a novel mobile TEE-based security framework that can efficiently execute the entire DNN with minimal inference time overhead on a resource-constrained mobile TEE. We developed the first fine-grained structured pruning method that can accurately identify and remove redundant neurons with minimal impact on inference accuracy and achieve significantly reduced retraining iterations. In addition, we developed a low-level re-coding optimization mechanism that reduces the memory usage of DNNs and facilitates their execution in resource-constrained mobile TEEs. We further designed an adaptive partitioning method that dynamically partitions the pruned DNNs into partitions based on the memory constraint of the mobile TEE.&nbsp;</p> <p>The new technologies resulting from this project can provide new directions for software and hardware architecture design of deep learning on heterogeneous mobile devices. Moreover, the outcomes of this project could significantly benefit the entire spectrum of deep learning across various research domains, including computer architecture, mobile sensing, cyber security, and human-computer interaction research areas. By integrating the research results with the undergraduate and graduate curricula and outreach activities, this project has greatly impacted the education and training of researchers and engineers for computer architecture, security, theory and algorithms, and systems. Results are disseminated through scholarly publications and active outreach to the wireless and mobile industry through Temple&rsquo;s industry events and connections. The project provided students with rich mentoring and research experience in experiment design, prototyping, and data analysis. Two Ph.D. students got support from this project and gained significant results. Additional master students and eight undergraduate students also participated in the project through summer internships and independent study programs.&nbsp;</p><br> <p>  Last Modified: 01/29/2024<br> Modified by: Yan&nbsp;Wang</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  This project explored designing a software accelerator that enables the broad deployment of heavy-cost deep learning models into resource-constrained, heterogeneous mobile edge devices (e.g., low-cost sensing platforms and IoT devices). More specifically, this project analyzed distinct deep-learning behaviors on mobile edge devices and designed different strategies to improve the efficiency of multiple deep-learning-based inference models. Furthermore, innovative compression algorithms are developed to adjust the complexity of different deep learning models and reduce their energy and memory consumption on mobile edge devices. Finally, this project developed power-centric reallocation algorithms to verify and deploy mobile-friendly deep learning models in multiple application domains. Particularly, we accomplished the following aspects. (1) Global Mixture Pruning for Further Flops Compression via Neuron Bond. (2) Solving the WiFi Sensing Dilemma in Reality Leveraging Conformal Prediction. (3) Secure and Efficient Mobile DNN Using Trusted Execution Environments.   (1) Global Mixture Pruning for Further Flops Compression via Neuron Bond. Neuron network pruning is effective in compressing pre-trained CNNs for their deployment on low-end edge devices. However, only some works have focused on reducing the computational cost of pruning and inference. We found that existing pruning methods usually remove parameters without fine-grained impact analysis, making it hard to achieve an optimal solution. We developed a global mixture pruning mechanism to effectively reduce the computational cost of CNNs while maintaining a high weight compression ratio and model accuracy. We proposed removing neuron bonds in the convolution layer and fully connected layers to skip the corresponding computation for generating each pixel of the output map. We also designed an influence factor to analyze the importance of neuron bonds and weights in a fine-grained way so that our approach could significantly reduce the pruning iterations by only performing a one-shot pruning when the total number of unimportant parameters reaches the compress ratio. Therefore, our approach required fewer retraining iterations to recover the accuracy of the network.   (2) Solving the WiFi Sensing Dilemma in Reality Leveraging Conformal Prediction. With the broad deployment of smart environments and IoT devices, WiFi sensing has demonstrated its great convenience and contactless sensing capabilities in supporting various applications. However, designing a ubiquitous WiFi sensing system for heterogeneous scenarios in practice is still a big dilemma, as the system performs poorly when the testing data is significantly different from the training data caused by domain variations. To address this dilemma, we conducted a comprehensive study of the domain variation problems in various WiFi sensing applications and developed a holistic WiFi sensing framework using conformal prediction that can ensure high prediction accuracy when facing different domain variations in reality. Novel kernel density-based nonconformity measure and cross-domain conformal prediction were developed to achieve more accurately determine the most possible class(es) of the input data. The proposed framework is reliazed to study its effectiveness in typical WiFi sensing applications (i.e., user identification, activity classification, and gesture recognition).   (3) Secure and Efficient Mobile DNN Using Trusted Execution Environments. As mobile applications increasingly rely on deep neural networks (DNNs) for their powerful inference capabilities, there is a growing need for secure DNN execution on mobile devices. Towards this end, hardware-based trusted execution environments on mobile devices (mobile TEEs) such as ARM TrustZone are being utilized for secure DNN execution. This project developed a novel mobile TEE-based security framework that can efficiently execute the entire DNN with minimal inference time overhead on a resource-constrained mobile TEE. We developed the first fine-grained structured pruning method that can accurately identify and remove redundant neurons with minimal impact on inference accuracy and achieve significantly reduced retraining iterations. In addition, we developed a low-level re-coding optimization mechanism that reduces the memory usage of DNNs and facilitates their execution in resource-constrained mobile TEEs. We further designed an adaptive partitioning method that dynamically partitions the pruned DNNs into partitions based on the memory constraint of the mobile TEE.   The new technologies resulting from this project can provide new directions for software and hardware architecture design of deep learning on heterogeneous mobile devices. Moreover, the outcomes of this project could significantly benefit the entire spectrum of deep learning across various research domains, including computer architecture, mobile sensing, cyber security, and human-computer interaction research areas. By integrating the research results with the undergraduate and graduate curricula and outreach activities, this project has greatly impacted the education and training of researchers and engineers for computer architecture, security, theory and algorithms, and systems. Results are disseminated through scholarly publications and active outreach to the wireless and mobile industry through Temples industry events and connections. The project provided students with rich mentoring and research experience in experiment design, prototyping, and data analysis. Two Ph.D. students got support from this project and gained significant results. Additional master students and eight undergraduate students also participated in the project through summer internships and independent study programs.     Last Modified: 01/29/2024       Submitted by: YanWang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
