<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[PostDoctoral Research Fellowship]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Fellowship Award</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Stefaan De Winter</SignBlockName>
<PO_EMAI>sgdewint@nsf.gov</PO_EMAI>
<PO_PHON>7032922599</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This award is made as part of the FY 2020 Mathematical Sciences Postdoctoral Research Fellowships Program. Each of the fellowships supports a research and training project at a host institution in the mathematical sciences, including applications to other disciplines, under the mentorship of a sponsoring scientist. The title of the project for this fellowship to Hunter S. Chase is " Model theory and machine learning." The host institution for the fellowship is University of Maryland and the sponsoring scientist is Michael Laskowski.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/12/2020</MinAmdLetterDate>
<MaxAmdLetterDate>03/12/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2002165</AwardID>
<Investigator>
<FirstName>Hunter</FirstName>
<LastName>Chase</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hunter S Chase</PI_FULL_NAME>
<EmailAddress/>
<NSF_ID>000811280</NSF_ID>
<StartDate>03/12/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Chase, Hunter Sato]]></Name>
<CityName>Chicago</CityName>
<ZipCode>60607</ZipCode>
<PhoneNumber/>
<StreetAddress/>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM/>
<ORG_LGL_BUS_NAME/>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland Department of Mathematics]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207424015</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>060Y00</Code>
<Text>Workforce (MSPRF) MathSciPDFel</Text>
</ProgramElement>
<ProgramReference>
<Code>9219</Code>
<Text>POSTDOCTORAL FELLOWSHIPS IN MATH SCIENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~150000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project explored connections between model theory and the foundations of machine learning. Model theory is a branch of mathematical logic that studies the structure of the definable sets in an arbitrary mathematical structure. Within model theory, a number of dividing lines have been identified, which distinguish between theories that exhibit structure and those that exhibit "wild" behavior. Many of these dividing lines can be expressed in local combinatorial terms. These combinatorial phenomena frequently appear in a machine learning context as well, characterizing which set systems are learnable for different notions of machine learning. Our work continued a program to develop a dialogue between model theory and machine learning via this common machinery to exchange and develop tools and techniques.</p> <p>We studied a framework called machine teaching, in which a teacher and learner cooperate to establish functions that allow the learner to recover a particular concept from a concept class based on a small number of representative points chosen by the teacher. We showed that classes of finite Littlestone dimension, of any cardinality, admitted a teaching function. We also showed that countable classes of VC-dimension 1 admitted a teaching function. Moreover, such a function could be constructed concept by concept, with no knowledge of subsequent concepts other than that the entire class had VC-dimension 1.</p> <p>To contribute to the mathematical community, I also mentored a graduate student as she read papers in computability theory.</p><br> <p>  Last Modified: 10/26/2024<br> Modified by: Hunter&nbsp;S&nbsp;Chase</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  This project explored connections between model theory and the foundations of machine learning. Model theory is a branch of mathematical logic that studies the structure of the definable sets in an arbitrary mathematical structure. Within model theory, a number of dividing lines have been identified, which distinguish between theories that exhibit structure and those that exhibit "wild" behavior. Many of these dividing lines can be expressed in local combinatorial terms. These combinatorial phenomena frequently appear in a machine learning context as well, characterizing which set systems are learnable for different notions of machine learning. Our work continued a program to develop a dialogue between model theory and machine learning via this common machinery to exchange and develop tools and techniques.   We studied a framework called machine teaching, in which a teacher and learner cooperate to establish functions that allow the learner to recover a particular concept from a concept class based on a small number of representative points chosen by the teacher. We showed that classes of finite Littlestone dimension, of any cardinality, admitted a teaching function. We also showed that countable classes of VC-dimension 1 admitted a teaching function. Moreover, such a function could be constructed concept by concept, with no knowledge of subsequent concepts other than that the entire class had VC-dimension 1.   To contribute to the mathematical community, I also mentored a graduate student as she read papers in computability theory.     Last Modified: 10/26/2024       Submitted by: HunterSChase]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
