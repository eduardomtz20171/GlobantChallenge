<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: Frameworks: Beyond the BLAS: A Framework for Accelerating Computational and Data Science]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2020</AwardEffectiveDate>
<AwardExpirationDate>04/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>369280.00</AwardTotalIntnAmount>
<AwardAmount>369280</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sheikh Ghafoor</SignBlockName>
<PO_EMAI>sghafoor@nsf.gov</PO_EMAI>
<PO_PHON>7032927116</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Traditional scientific and machine learning high-performance computing software is often cast in terms of a set of fundamental operations, including the linear algebra functionality that underlies many applications.  For this reason, research into and development of open-source linear algebra software libraries has been a science infrastructure priority for decades.  An emerging trend that has disrupted this field is the recognition that scientific discovery can be made faster and/or more cost efficient by lowering the precision of computations, utilizing non-standard data types, and developing custom computational kernels.  The project will leverage insights into how to structure the required software so that the combinatorial explosion in software complexity remains manageable.  The outcome of the project will be a modern linear algebra software framework and application-focused libraries that will support future generations of computational applications in academia, at the national labs, and in industry.  In addition, the project will impact the training of the next generation of high-performance computing professions and help remove barriers into the field for members of traditionally underrepresented groups.&lt;br/&gt;&lt;br/&gt;The proposed work will build on previous NSF-sponsored research in order to address the implementation of expanded precision (EP), mixed precision (MP), and mixed domain (MD) algorithms simultaneously in a single software solution.  Insights gained from a recent demonstration of MP/MD matrix multiplication will be extended by adding low precision types like float16 and bfloat16 and extended precision types like double-double.  The target Basic Linear Algebra Subprograms (BLAS) functionality will be expanded to all level-1, level-2, and level-3 operations which in turn will support new research on how best to exploit MP/MD for LAPACK functionality.  The new BLAS-like Library Instantiation Software (BLIS) framework will also be updated to provide the flexibility required to integrate extended dense linear algebra (DLA) operations. This flexible DLA framework will then be used to implement key functionality in computational and data science:  tensor contraction and factorization operations important to quantum chemistry (QC) and high-performance primitives for machine learning.  As a demonstration, these capabilities will be used to build state-of-the-art QC codes to perform coupled cluster polarization propagator and tensor-factorized coupled cluster calculations with full EP/MP/MD functionality, and the machine learning kernels will be integrated into computer vision and image recognition workflows.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/09/2020</MinAmdLetterDate>
<MaxAmdLetterDate>04/09/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2003931</AwardID>
<Investigator>
<FirstName>Devin</FirstName>
<LastName>Matthews</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Devin A Matthews</PI_FULL_NAME>
<EmailAddress><![CDATA[damatthews@smu.edu]]></EmailAddress>
<NSF_ID>000800164</NSF_ID>
<StartDate>04/09/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Southern Methodist University]]></Name>
<CityName>DALLAS</CityName>
<ZipCode>752051902</ZipCode>
<PhoneNumber>2147684708</PhoneNumber>
<StreetAddress><![CDATA[6425 BOAZ ST RM 130]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX24</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>D33QGS3Q3DJ3</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>SOUTHERN METHODIST UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>S88YPE3BLV66</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Southern Methodist University]]></Name>
<CityName>Dallas</CityName>
<StateCode>TX</StateCode>
<ZipCode>752750302</ZipCode>
<StreetAddress><![CDATA[6425 BOAZ]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX32</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>800400</Code>
<Text>Software Institutes</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>077Z</Code>
<Text>CSSI-1: Cyberinfr for Sustained Scientif</Text>
</ProgramReference>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8004</Code>
<Text>Software Institutes</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~369280</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p id="docs-internal-guid-13781562-7fff-c14a-582f-b33c8cbad30b" dir="ltr"><span>Computer simulations for scientific computing, machine learning, and data analysis accelerate, improve, and expand scientific insight, and are major drivers of American economic competitiveness. In simulation software, linear algebra problems often constitute the most basic and yet critical building blocks of the computation. As a result, software libraries (bundles of specialized code) that efficiently solve linear algebra problems fundamentally support sustained innovation in science. This project expanded the award-winning BLAS-like Library Instantiation Software (BLIS), which is now arguably the premier open-source software library for basic linear algebra computations.&nbsp; It has directly and indirectly impacted discovery in academia, at the national labs, and in industry. It has been incorporated into software distributed by established companies (including AMD, Nvidia, and Oracle) as well as startups, thus positively affecting the competitiveness of American technology firms.&nbsp; Sustainability beyond the funded project has been assured by the purposeful building of a community. Through educational outreach, the project has lowered barriers to entry into the field. The project involved research staff and students who are members of traditionally underrepresented groups.</span></p> <p>&nbsp;</p> <p dir="ltr"><span>The BLAS (Basic Linear Algebra Subprograms) are a de facto standard for software, providing building blocks for performing basic linear algebra operations. The problem with the standard BLAS and its implementation has been that it has not changed since its inception in the 1970s and 80s, which can hinder innovation of high-performance software in important fields such as chemistry/physics and artificial intelligence.&nbsp; Upon commencement of the project, the BLIS software provided a highly-portable high-performance, but traditional, BLAS implementation for general-purpose processors (CPUs).&nbsp; Through completion of the project, developers and users can now flexibly extend the supported functionality to new operations and architectures of importance to modern applications in scientific computing, machine learning, and data analysis.&nbsp; BLIS also now includes built-in support for linear algebra functionality far surpassing the BLAS by allowing for inputs and outputs of varying precision. In other words, what was a static interface typically implemented as static code is now an extensible interface supported by a flexible framework for its instantiation.&nbsp; This has transformed the BLAS from a highly useful, but often restrictive, infrastructure for sustained scientific computing to one that will flexibly support future scientific innovation.</span></p> <p>&nbsp;</p><br> <p>  Last Modified: 09/15/2024<br> Modified by: Devin&nbsp;A&nbsp;Matthews</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Computer simulations for scientific computing, machine learning, and data analysis accelerate, improve, and expand scientific insight, and are major drivers of American economic competitiveness. In simulation software, linear algebra problems often constitute the most basic and yet critical building blocks of the computation. As a result, software libraries (bundles of specialized code) that efficiently solve linear algebra problems fundamentally support sustained innovation in science. This project expanded the award-winning BLAS-like Library Instantiation Software (BLIS), which is now arguably the premier open-source software library for basic linear algebra computations. It has directly and indirectly impacted discovery in academia, at the national labs, and in industry. It has been incorporated into software distributed by established companies (including AMD, Nvidia, and Oracle) as well as startups, thus positively affecting the competitiveness of American technology firms. Sustainability beyond the funded project has been assured by the purposeful building of a community. Through educational outreach, the project has lowered barriers to entry into the field. The project involved research staff and students who are members of traditionally underrepresented groups.      The BLAS (Basic Linear Algebra Subprograms) are a de facto standard for software, providing building blocks for performing basic linear algebra operations. The problem with the standard BLAS and its implementation has been that it has not changed since its inception in the 1970s and 80s, which can hinder innovation of high-performance software in important fields such as chemistry/physics and artificial intelligence. Upon commencement of the project, the BLIS software provided a highly-portable high-performance, but traditional, BLAS implementation for general-purpose processors (CPUs). Through completion of the project, developers and users can now flexibly extend the supported functionality to new operations and architectures of importance to modern applications in scientific computing, machine learning, and data analysis. BLIS also now includes built-in support for linear algebra functionality far surpassing the BLAS by allowing for inputs and outputs of varying precision. In other words, what was a static interface typically implemented as static code is now an extensible interface supported by a flexible framework for its instantiation. This has transformed the BLAS from a highly useful, but often restrictive, infrastructure for sustained scientific computing to one that will flexibly support future scientific innovation.        Last Modified: 09/15/2024       Submitted by: DevinAMatthews]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
