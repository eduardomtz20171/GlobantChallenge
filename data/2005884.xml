<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[SHF: Small: Automatic, adaptive and massive parallel data processing on GPU/RDMA clusters in both synchronous and asynchronous modes]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>539783</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The computing ecosystem in both hardware and software is in a critical transition time, coming from several technology crises and inevitable trends. First, the continued performance improvement in general-purpose processors is no longer realistic. Second, conventional processors are increasingly inefficient in both performance and power consumption for various data-intensive applications. Finally, the deep software stack that has been developed for several decades, from instruction-set architecture all the way to the programming layer in the existing ecosystem, has added cumbersome processing and even unnecessary overhead in computing. To address the above-mentioned issues, this project remedies the computing ecosystem in an accelerator-based way. GPU (Graphic Processing Unit) and RDMA (Remote Data Memory Access) are the two external hardware accelerators considered in the project. It aims to turn efficient asynchronous computing into a reality on clusters of hardware accelerators of GPU and RDMA adaptively and automatically by removing three technical barriers in the existing ecosystem: (1) the programming-model barrier, (2) the hardware abstraction barrier, and (3) the automation barrier. The project strives to make broad and transformational impact. It is expected to influence the data-processing research community with new algorithms and effective systems implementation, and influence industries to improve their production systems in their daily computing operations serving society. The developed algorithms, source code and measurements are available online for a public and wide usage, benefiting both industrial and academic researchers. The research training to both undergraduate and graduate students address the concerns of lacking hardware-acceleration and data-analytics professionals in information technology and computing industries. The curriculum development introduces related research results to classrooms and the outreach activities encourage high school students to be interested in computing related college education. &lt;br/&gt;&lt;br/&gt;The existing computing environment does not provide programming models for asynchronous execution. It is even harder for asynchronous programming on GPU/RDMA clusters. The execution-model difference between CPUs and GPUs makes the system lack a common hardware abstraction for GPU computing and for RDMA communication and management. Asynchronous programming is hard, and an automatic tool to ensure its correctness and efficiency is highly desirable. This research project bridges the gap between asynchronous computing and GPU/RDMA. It develops an autonomous memory pool (AMP) interfacing GPU/RDMA clusters, where an intermediate representation is proposed to abstract the GPU execution and AMP constructed by an RDMA. A set of intermediate representations are developed to support asynchronous programming, so that users can easily express asynchronous computing in programming. In addition, an intermediate representation is developed to allow conventional synchronous programming to become automated asynchronous execution code. The system is tested and evaluated using representative data-processing workloads on large GPU/RDMA clusters.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/30/2020</MinAmdLetterDate>
<MaxAmdLetterDate>08/27/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2005884</AwardID>
<Investigator>
<FirstName>Hao</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hao Wang</PI_FULL_NAME>
<EmailAddress><![CDATA[wang.2721@osu.edu]]></EmailAddress>
<NSF_ID>000791327</NSF_ID>
<StartDate>06/30/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Xiaodong</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiaodong Zhang</PI_FULL_NAME>
<EmailAddress><![CDATA[zhang@cse.ohio-state.edu]]></EmailAddress>
<NSF_ID>000416471</NSF_ID>
<StartDate>06/30/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName>COLUMBUS</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress><![CDATA[1960 KENNY RD]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>DLWBSLWAJWR1</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>MN4MDDMN8529</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The Ohio State University]]></Name>
<CityName>Columbus</CityName>
<StateCode>OH</StateCode>
<ZipCode>432101016</ZipCode>
<StreetAddress><![CDATA[1960 Kenny Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>779800</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~450000</FUND_OBLG>
<FUND_OBLG>2021~89783</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>We are in the era of data-centric computing by hardware accelerations. However, most existing algorithms are only designed for general-purpose computing environment, including parallel algorithms, which are largely machine independent. For any effecient program execution today, it must rely on three dynamic and hardware dependent factors: low algorithm complexity, high locality and high parallelism. In this project, we have made strong cases for applying hardware accelerators to significantly improve the performance of several important applications in machine learning and databases. We have also enhanced the existing Remote Procedure Call infrastructure by embeding RDMA into it for low latency of remote memory accesses and high throughput. All the results have been published in top computer science conferences and journals, and all related software are in open-source format for public usage.&nbsp;&nbsp;</p> <p>This project has also made education impact. Two Ph.D. students are supported in the project. Several undergraduate students participated in the project. The research results have been introduced in PI's classrooms of computer architecture and parallel processing. The textbook witten by the PI, entitled Data Management: Interactions with Computer Architecture and Systems has been published by the Cambridge Press. Several new research results from this project are introduced in the book.&nbsp;</p> <p><span>It is worth mentioning that an open-source software and its VLDB 2013 paper on Haddop-GIS are recognized by the VLDB Test of Time Award in 2024 for our pioneer leadership of creating a new ecosystem for spatial data processing on large-scale clusters of commodity processors by open-source software. This high impact work was supported by two NSF grants awarded in 2011. We are confident that research results and related open-source software supported by this NSF grant will make impact in the future.&nbsp;</span></p> <p>&nbsp;</p><br> <p>  Last Modified: 08/06/2024<br> Modified by: Xiaodong&nbsp;Zhang</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  We are in the era of data-centric computing by hardware accelerations. However, most existing algorithms are only designed for general-purpose computing environment, including parallel algorithms, which are largely machine independent. For any effecient program execution today, it must rely on three dynamic and hardware dependent factors: low algorithm complexity, high locality and high parallelism. In this project, we have made strong cases for applying hardware accelerators to significantly improve the performance of several important applications in machine learning and databases. We have also enhanced the existing Remote Procedure Call infrastructure by embeding RDMA into it for low latency of remote memory accesses and high throughput. All the results have been published in top computer science conferences and journals, and all related software are in open-source format for public usage.   This project has also made education impact. Two Ph.D. students are supported in the project. Several undergraduate students participated in the project. The research results have been introduced in PI's classrooms of computer architecture and parallel processing. The textbook witten by the PI, entitled Data Management: Interactions with Computer Architecture and Systems has been published by the Cambridge Press. Several new research results from this project are introduced in the book.   It is worth mentioning that an open-source software and its VLDB 2013 paper on Haddop-GIS are recognized by the VLDB Test of Time Award in 2024 for our pioneer leadership of creating a new ecosystem for spatial data processing on large-scale clusters of commodity processors by open-source software. This high impact work was supported by two NSF grants awarded in 2011. We are confident that research results and related open-source software supported by this NSF grant will make impact in the future.        Last Modified: 08/06/2024       Submitted by: XiaodongZhang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
