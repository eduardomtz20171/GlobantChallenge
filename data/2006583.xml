<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[III: Small: Accessible and Interpretable Machine Reading Methods for Extracting Structured Information from Text]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>499945.00</AwardTotalIntnAmount>
<AwardAmount>499945</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hector Munoz-Avila</SignBlockName>
<PO_EMAI>hmunoz@nsf.gov</PO_EMAI>
<PO_PHON>7032924481</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computers, the Internet, and cheap storage promote the acquisition and collection of vast quantities of data. There is a seemingly infinite supply of text documents which contain critical scientific, socio-political, and business insights â€“ far more than can be read by a human. Within the natural language processing (NLP) domain, the field of information extraction (IE) targets exactly this problem, but it requires its practitioners to have expertise either in linguistics, machine learning, or both. Consequently, the majority of the advancements in the field of IE are difficult to access by domain experts such as epidemiologists, biologists, and economists.  This project will empower these domain experts to develop and deploy IE systems targeting their own particular needs without requiring expertise in NLP, linguistics, or machine learning, which, in turn, will dramatically impact the process, pace, and productivity of conducting critical scientific research and collaboration, as experts could have far more ready access to the knowledge most essential to them and their research (both in their domain and adjacent domains).  The products of this work will be shared across the scientific community through a series of outreach efforts such as video courses, publications, and a workshop at a high-visibility conference. To broaden participation, outreach activities (including deepening collaborations with institutional colleagues and local community outreach) will be done with an emphasis on groups who are historically underrepresented in academia. &lt;br/&gt;&lt;br/&gt;The planned work will be accomplished through a human-technology partnership, where domain experts specify their information need at the level they find intuitive, (e.g., phosphorylation acts on proteins). The system will then extend techniques from the adjacent field of program synthesis to convert these high-level, abstract specifications into low-level grammars (i.e., sets of hierarchical information extraction rules) which can be executed in order to extract the desired information from text. Crucially, the specification requires no linguistic knowledge, making it accessible to a broader population. The need for domain-specific entities (e.g., names of proteins) will be addressed through an entity discovery procedure that incorporates techniques for detecting multi-word entity candidates and inferring their semantic types (e.g., PROTEIN). To ensure that the product of the system is readily interpretable and easily extensible, a series of user studies will be conducted to discover the key characteristics of rules and grammars that affect their interpretability and maintainability. Through this combined effort, several datasets and software products will be produced and made available to the wider community. This includes (but is not limited to) (a) a dataset of event specifications and the corresponding automatically synthesized rules for several domains (b) a dataset of human judgements of grammar interpretability, and (c) models which can serve as automatic proxies for the more expensive human evaluation of interpretability. All data will be anonymized and released under the Open Data Commons Public Domain Dedication &amp; License, which allows users to freely share, modify, and use this data, in the hope that this effort will be exploited further. To ensure as wide an audience as possible, the software and techniques developed in this work including the rule synthesis framework, a pipeline for entity discovery, and any generated user interfaces, will be released as open-source software products (under an Apache 2.0 open source license).&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/02/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/13/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2006583</AwardID>
<Investigator>
<FirstName>Mihai</FirstName>
<LastName>Surdeanu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mihai Surdeanu</PI_FULL_NAME>
<EmailAddress><![CDATA[msurdeanu@email.arizona.edu]]></EmailAddress>
<NSF_ID>000617252</NSF_ID>
<StartDate>06/13/2022</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gustave</FirstName>
<LastName>Hahn-Powell</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gustave V Hahn-Powell</PI_FULL_NAME>
<EmailAddress><![CDATA[hahnpowell@arizona.edu]]></EmailAddress>
<NSF_ID>000749596</NSF_ID>
<StartDate>07/02/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Rebecca</FirstName>
<LastName>Sharp</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rebecca Sharp</PI_FULL_NAME>
<EmailAddress><![CDATA[bsharp@email.arizona.edu]]></EmailAddress>
<NSF_ID>000787976</NSF_ID>
<StartDate>07/02/2020</StartDate>
<EndDate>04/14/2022</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Marco Antonio</FirstName>
<LastName>Valenzuela-Escarcega</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marco Antonio Valenzuela-Escarcega</PI_FULL_NAME>
<EmailAddress><![CDATA[marcov@email.arizona.edu]]></EmailAddress>
<NSF_ID>000787952</NSF_ID>
<StartDate>07/02/2020</StartDate>
<EndDate>06/13/2022</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>TUCSON</CityName>
<ZipCode>85721</ZipCode>
<PhoneNumber>5206266000</PhoneNumber>
<StreetAddress><![CDATA[845 N PARK AVE RM 538]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>ED44Y3W6P7B9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARIZONA</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>Tucson</CityName>
<StateCode>AZ</StateCode>
<ZipCode>857210077</ZipCode>
<StreetAddress><![CDATA[1040 E. 4th Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>736400</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~336201</FUND_OBLG>
<FUND_OBLG>2021~163744</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-372cabf1-7fff-f18b-252a-2e20184e1973"> <span id="docs-internal-guid-38b403ad-7fff-2158-57ad-58408ace2b16"> </span></span></p> <p dir="ltr"><span>Today's world is flooded with information.&nbsp; In just the biomedical domain, over 1 million new papers are published in English each year.&nbsp; Searching through this information comprehensively and precisely to find answers to questions is an unsolved problem.&nbsp;</span></p> <p><span>Many sophisticated tools and techniques have been developed over the years to assist with this process, but most of them remain generally unknown and inaccessible to the public.&nbsp;</span></p> <p>Large Language Models (LLMs) and other types of deep neural networks have impressive generalization capabilities, but these models are compute intensive black boxes.&nbsp; Symbolic systems like programming languages are readily interpretable, directly editable, and often efficient to execute, but tend to generalize poorly.&nbsp; Until very recently, crafting even small programs was mostly a manual process requiring specialized expertise.&nbsp;</p> <p>Neural and symbolic approaches to artificial intelligence possess complementary strengths.&nbsp; Can we democratize these techniques for use by non-experts and leverage the power of deep neural networks (ex. LLMs) to produce small, fast, and human editable programs (symbolic systems) that fulfill a particular information need?&nbsp;&nbsp;This project investigates methods for synthesizing symbolic and deep neural network methods to accomplish this goal.</p> <p dir="ltr">Our efforts have resulted in novel neuro-symbolic methods for generating information extraction programs through a process that requires a layuser to only provide a handful of examples of their information need.</p> <p dir="ltr"><span>We have produced </span>open source software, one textbook, two international workshops on pattern-based approaches in the age of deep learning (with a proposal for a third under review),&nbsp;11&nbsp;peer-reviewed conference publications, and 1 journal paper.&nbsp; We were also able to provide research-based training to five&nbsp;students (2 undergraduates and 3 graduate students).&nbsp;</p> <p>&nbsp;</p><br> <p>  Last Modified: 10/27/2024<br> Modified by: Mihai&nbsp;Surdeanu</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[       Today's world is flooded with information. In just the biomedical domain, over 1 million new papers are published in English each year. Searching through this information comprehensively and precisely to find answers to questions is an unsolved problem.   Many sophisticated tools and techniques have been developed over the years to assist with this process, but most of them remain generally unknown and inaccessible to the public.   Large Language Models (LLMs) and other types of deep neural networks have impressive generalization capabilities, but these models are compute intensive black boxes. Symbolic systems like programming languages are readily interpretable, directly editable, and often efficient to execute, but tend to generalize poorly. Until very recently, crafting even small programs was mostly a manual process requiring specialized expertise.   Neural and symbolic approaches to artificial intelligence possess complementary strengths. Can we democratize these techniques for use by non-experts and leverage the power of deep neural networks (ex. LLMs) to produce small, fast, and human editable programs (symbolic systems) that fulfill a particular information need?This project investigates methods for synthesizing symbolic and deep neural network methods to accomplish this goal.   Our efforts have resulted in novel neuro-symbolic methods for generating information extraction programs through a process that requires a layuser to only provide a handful of examples of their information need.   We have produced open source software, one textbook, two international workshops on pattern-based approaches in the age of deep learning (with a proposal for a third under review),11peer-reviewed conference publications, and 1 journal paper. We were also able to provide research-based training to fivestudents (2 undergraduates and 3 graduate students).        Last Modified: 10/27/2024       Submitted by: MihaiSurdeanu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
