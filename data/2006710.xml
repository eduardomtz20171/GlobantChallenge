<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[III: Small: Collaborative Research: Neural Volume Visualization]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2020</AwardEffectiveDate>
<AwardExpirationDate>07/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>198898.00</AwardTotalIntnAmount>
<AwardAmount>198898</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032927347</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Data visualization is a key component to discovery for domain experts in a variety of scientific fields, ranging from atmospheric and ocean sciences, energy science, geosciences, and computational chemistry. Within these domains, visualization techniques for 3D volumetric data are commonly used to understand datasets produced by computational simulations. In turn, the insights gained through volume visualization are used to inform an expert on new simulations to run, leading to a cycle of visual analysis and simulation that supports a domain expert's workflow. Yet, this cycle is often impeded by the sheer size and complexity of the data, typified as high spatial resolution, time-varying, and multivariate, leading to two main problems. First, there are practical limitations to data access. Simulations are typically run on high-performance computing clusters, thus it is time and memory consuming to transfer data from these computational resources. Secondly, it is challenging to understand relationships between volumes across the aforementioned space of parameters. This project will address these problems through the development of deep learning-based volume visualization techniques that are compressive, interactive, trustworthy, and enable intuitive analysis. This research will study how now-standard volume visualization techniques can be decomposed into learnable components and fixed-function visualization operations, producing surrogate visualization models that will support experts across a variety of domains by facilitating visual analysis, and improving the discovery of relationships within complex datasets. This project will also hold local workshops for training graduate students across different fields to use the developed visualization methods in their respective domains.&lt;br/&gt;&lt;br/&gt;The development of surrogate models for volume visualization represents a new perspective on how to use machine learning for data visualization, where such models will be designed to reason about visualization processes, namely volume rendering and isosurfacing. This project will consider a full design space for learning surrogate models from different aspects of volume visualization, namely (1) learned volumetric representations such as function-space neural networks and volumetric feature embeddings, (2) parameters of visualization processes such as transfer functions and isovalues, and (3) the visualization process itself such as image formation in volume rendering or surface creation in isosurfacing. Furthermore, these surrogates will generalize to temporal sequences, multivariate volumes, and ensembles of volume simulations. Additionally, new techniques will be developed to utilize these surrogate models to improve volume visualization in three scenarios. Specifically the project will (1) inform end users about the trustworthiness of using machine learning for volume visualization, (2) learn simpler visual interfaces for user interaction, and finally (3) utilize latent representations of simulation factors for exploring complex relationships. The insights of this work go beyond just volume visualization, and they will offer new approaches to couple machine learning with visualization as a whole. This project will also disseminate the results, in the form of data used to train models, the models themselves, and software for both model training and visual exploration. Further, the investigators will collaborate with domain experts at their respective institutions to validate the quality, usability, and trustworthiness of the surrogate models, as well as translate the developed research into the practice of these domain experts.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/31/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/31/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2006710</AwardID>
<Investigator>
<FirstName>Joshua</FirstName>
<LastName>Levine</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joshua A Levine</PI_FULL_NAME>
<EmailAddress><![CDATA[josh@email.arizona.edu]]></EmailAddress>
<NSF_ID>000635850</NSF_ID>
<StartDate>07/31/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>TUCSON</CityName>
<ZipCode>85721</ZipCode>
<PhoneNumber>5206266000</PhoneNumber>
<StreetAddress><![CDATA[845 N PARK AVE RM 538]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>ED44Y3W6P7B9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARIZONA</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>Tucson</CityName>
<StateCode>AZ</StateCode>
<ZipCode>857210077</ZipCode>
<StreetAddress><![CDATA[1040 E. 4th Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>736400</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~198898</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project contributed new techniques for managing and visualizing large-scale scientific data.&nbsp; Data produced from numerical simulations often comes in the form of spatially-referenced fields that can be time-varying, multivariate, and dependent on the parameters of a simulation.&nbsp; The size of the data can impede interactive analysis, as users must contend with high demands on data storage, and high latency in querying the data.&nbsp; Motivated by these challenges, this project focused on the development of novel techniques for data representations that are compact, trustworthy, and enable efficient querying for interactive visual analysis.&nbsp; A novel method for representing volumetric fields was developed, where coordinate-based neural networks are used to represent fields in a highly compressive manner.&nbsp; Notably, the method permits querying of the field in its compressive form, as well as features of the field.&nbsp; This method was extended towards directly preserving quantities that are of interest for visual analysis, namely flow-based features of a time-varying vector field, and models specifically designed to support interactive querying of features that would otherwise require expensive computation.&nbsp; Moreover, this project contributed a method for representing a set of fields that vary over the parameter space of simulation, in turn giving a link between user-specified features of a field, and interpretable parameters of the simulation.&nbsp; These methods have been shown to give compressive yet accurate representations of field-based data that enable interactive visual analysis, thus advancing the fields of scientific visualization and deep learning.</p><br> <p>  Last Modified: 11/30/2024<br> Modified by: Joshua&nbsp;A&nbsp;Levine</p></div> <div class="porSideCol" ><div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2024/2006710/2006710_10691639_1732992681400_neurcomp--rgov-214x142.png" original="/por/images/Reports/POR/2024/2006710/2006710_10691639_1732992681400_neurcomp--rgov-800width.png" title="Compressive neural representations of volumetric scalar fields"><img src="/por/images/Reports/POR/2024/2006710/2006710_10691639_1732992681400_neurcomp--rgov-66x44.png" alt="Compressive neural representations of volumetric scalar fields"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Compressive representations of volumetric scalar fields were developed as part of this project. Shown here is a scalar field corresponding to a simulation of jet flames, compressed under varying sizes.</div> <div class="imageCredit">Matthew Berger</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Joshua&nbsp;A&nbsp;Levine <div class="imageTitle">Compressive neural representations of volumetric scalar fields</div> </div> </li></ul> </div> </div></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  This project contributed new techniques for managing and visualizing large-scale scientific data. Data produced from numerical simulations often comes in the form of spatially-referenced fields that can be time-varying, multivariate, and dependent on the parameters of a simulation. The size of the data can impede interactive analysis, as users must contend with high demands on data storage, and high latency in querying the data. Motivated by these challenges, this project focused on the development of novel techniques for data representations that are compact, trustworthy, and enable efficient querying for interactive visual analysis. A novel method for representing volumetric fields was developed, where coordinate-based neural networks are used to represent fields in a highly compressive manner. Notably, the method permits querying of the field in its compressive form, as well as features of the field. This method was extended towards directly preserving quantities that are of interest for visual analysis, namely flow-based features of a time-varying vector field, and models specifically designed to support interactive querying of features that would otherwise require expensive computation. Moreover, this project contributed a method for representing a set of fields that vary over the parameter space of simulation, in turn giving a link between user-specified features of a field, and interpretable parameters of the simulation. These methods have been shown to give compressive yet accurate representations of field-based data that enable interactive visual analysis, thus advancing the fields of scientific visualization and deep learning.     Last Modified: 11/30/2024       Submitted by: JoshuaALevine]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
