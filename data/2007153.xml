<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: CNS Core: Small: From Capture to Consumption: System Challenges in Pervasive 360-Degree Video Sharing]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>249910.00</AwardTotalIntnAmount>
<AwardAmount>315891</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>360-degree video allows users to explore a recorded scene at any angle from the camera position. This greater flexibility provided by the 360-degree video format has led to its increased popularity. However, widespread adoption has slowed because of the large amounts of resources required by the format. This work proposes methods to improve efficiency at each stage of the 360-degree video sharing path, from video capture at the sender side to consumption at the receiver side. &lt;br/&gt;&lt;br/&gt;The project addresses these challenges via four research thrusts. The first thrust explores approaches for generating high-quality frames during real-time stitching of multiple videos captured using commodity lenses. The proposed approach applies gradient decent to refine an initial rough stitching. The second thrust investigates mechanisms to spatially adapt content to be uploaded based on the available bandwidth. The third thrust aims to optimize the fine-grained representation of omnidirectional content to achieve high projection efficiency and view efficiency. The last thrust uses edge computing techniques to optimize the look-ahead window size on the receiver side to allow bandwidth-efficient content downloading.&lt;br/&gt;&lt;br/&gt;The techniques developed during the course of the project will allow users to enjoy more efficient 360-degree video streaming applications. These techniques are not only applicable to 360-degree video streaming but will also have applications in future generations of virtual reality (VR) technologies. The project will also motivate general student interest in computer science research, directly train students during the course of the projectâ€™s research, and contribute to curriculum development. &lt;br/&gt;&lt;br/&gt;The project will produce publications, code, data, and other research artifacts. All such artifacts will be made available publicly through the URLs http://www.cs.gmu.edu/~sqchen/ and http://www.cs.binghamton.edu/~yaoliu/ during the course of the project and remain available for at least five years after completion of the project. The code will be open sourced and will also be made available at code hosting website, e.g., GitHub.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/29/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/25/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2007153</AwardID>
<Investigator>
<FirstName>Songqing</FirstName>
<LastName>Chen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Songqing Chen</PI_FULL_NAME>
<EmailAddress><![CDATA[sqchen@gmu.edu]]></EmailAddress>
<NSF_ID>000240359</NSF_ID>
<StartDate>06/29/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[George Mason University]]></Name>
<CityName>FAIRFAX</CityName>
<ZipCode>220304422</ZipCode>
<PhoneNumber>7039932295</PhoneNumber>
<StreetAddress><![CDATA[4400 UNIVERSITY DR]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>11</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA11</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>EADLFP7Z72E5</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>GEORGE MASON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>H4NRWLFCDF43</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[George Mason University]]></Name>
<CityName>Fairfax</CityName>
<StateCode>VA</StateCode>
<ZipCode>220304422</ZipCode>
<StreetAddress><![CDATA[4400 University Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>11</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA11</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>171400</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>735400</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~249910</FUND_OBLG>
<FUND_OBLG>2021~65981</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Immservise applications, such as 360-degree video and virtual reality/augmented reality (VR/AR) streaming, promise to be the next killer applications on the Internet in various areas, including transportation, manufacturing, education and entertainment, public safety, and emergency responses, etc. However, generating, processing, delivering, and consuming such immersive content pose unprecedented challenges in the current practice due to a number of obstacles, ranging from high bandwidth demand to the high computing cost.&nbsp;<br /><br />The research supported by this award has explored these critical problems, and designed and implemented various novel and effective solutions to address them. To understand the problem in practice, we have conducted various measurement studies, for example, on the social VR platforms, and qualitatively and quantitatively uncover the underlying bottlenecks (e.g., the scalability). To more efficiently generate spherical content that is widely used in VR/AR applications, we have explored new designs based on spherical autoencoder to speed up the content processing. Our measurement study also shows that the synchronization between multiple users in AR is lacking, hindering the application development. We thus have designed more efficient and accurate algorithms for this purpose. Seeing that the harassment increasing quickly in the social VR environment, we have conducted user studies to understand the characteristics of the harassment behaviors, and designed and implemented a deep learning based detection scheme that can accurately and proactively detect such behaviors.&nbsp;</p> <p><br />The research results have been published and presented in various conferences and workshops, such as ACM Multimedia (MM) and IEEE Conference on Virtual Reality and 3D User Interfaces (VR).&nbsp;Several Ph.D. students who were supported partially by this award have been well trained, and have gained invaluable research experience from participating in this project.&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>  Last Modified: 10/19/2024<br> Modified by: Songqing&nbsp;Chen</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Immservise applications, such as 360-degree video and virtual reality/augmented reality (VR/AR) streaming, promise to be the next killer applications on the Internet in various areas, including transportation, manufacturing, education and entertainment, public safety, and emergency responses, etc. However, generating, processing, delivering, and consuming such immersive content pose unprecedented challenges in the current practice due to a number of obstacles, ranging from high bandwidth demand to the high computing cost.  The research supported by this award has explored these critical problems, and designed and implemented various novel and effective solutions to address them. To understand the problem in practice, we have conducted various measurement studies, for example, on the social VR platforms, and qualitatively and quantitatively uncover the underlying bottlenecks (e.g., the scalability). To more efficiently generate spherical content that is widely used in VR/AR applications, we have explored new designs based on spherical autoencoder to speed up the content processing. Our measurement study also shows that the synchronization between multiple users in AR is lacking, hindering the application development. We thus have designed more efficient and accurate algorithms for this purpose. Seeing that the harassment increasing quickly in the social VR environment, we have conducted user studies to understand the characteristics of the harassment behaviors, and designed and implemented a deep learning based detection scheme that can accurately and proactively detect such behaviors.    The research results have been published and presented in various conferences and workshops, such as ACM Multimedia (MM) and IEEE Conference on Virtual Reality and 3D User Interfaces (VR).Several Ph.D. students who were supported partially by this award have been well trained, and have gained invaluable research experience from participating in this project.              Last Modified: 10/19/2024       Submitted by: SongqingChen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
