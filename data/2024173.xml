<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: NRI: INT: Dense 3D Reconstruction of Dynamic Actors in Natural Environments using  Multiple Flying Cameras]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>860188.00</AwardTotalIntnAmount>
<AwardAmount>892188</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>While large-scale multi-camera domes have been developed for data collection in controlled laboratory settings it is not possible to achieve a similar level of measurement quality outdoors where there is much potential benefit to such data collection. For example, use of such measurements include the body dynamics of a running cheetah, or people, or analyzing herding behaviors of animals or birds. This leads to scientists relying on extremely inefficient and dangerous data collection methods. For example, biologists studying the behaviors of wild animals try to predict where the animals will be and place some cameras which only give some limited data at specific locations. This project addresses such challenges by exploring the research of methods and development of a large-scale data collection tool for high-resolution and multi-viewpoint visual recording and motion analysis of natural group behaviors (e.g., herds of animals or groups of people) in-the-wild over very large environments (e.g., desert plains or mountain sides) using a team of flying robots. &lt;br/&gt;&lt;br/&gt;This project develops computational models that integrate the fundamentals of computer vision and multi-agent control to measure the group of actors in 3D. Through the development of this system, this project will make major advances in technology at the intersection of perception and control that include: (1) a new study of methods for precise, rapid, and robust target motion forecasting and relative state estimation that estimates the 3D motion of the robots and actors quickly with strong uncertainty estimates; (2) a new decomposition of the perception-aware multi-objective multi-UAV safe motion planning problem, that allows long-term planning based on consistent actor forecasting uncertainty models and coverage objectives; (3) a new guaranteed safe but adaptive paradigm for reactive flight control that is able to generate safety maneuvers even under large disturbances and vehicle dynamics changes, and that can leverage prior flight experience for real-time adaptation; (4) new theory of 3D reconstruction for dynamic scenes captured by UAVs that will enable high-resolution mesh and skeletal reconstruction of the groups of actors. The research outcome will be disseminated through multiple educational activities.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/10/2020</MinAmdLetterDate>
<MaxAmdLetterDate>03/28/2023</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2024173</AwardID>
<Investigator>
<FirstName>Sebastian</FirstName>
<LastName>Scherer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sebastian Scherer</PI_FULL_NAME>
<EmailAddress><![CDATA[basti@andrew.cmu.edu]]></EmailAddress>
<NSF_ID>000614425</NSF_ID>
<StartDate>09/10/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kris</FirstName>
<LastName>Kitani</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kris Kitani</PI_FULL_NAME>
<EmailAddress><![CDATA[kkitani@cs.cmu.edu]]></EmailAddress>
<NSF_ID>000663208</NSF_ID>
<StartDate>09/10/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress><![CDATA[5000 FORBES AVE]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA12</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>U3NKNFLNQ613</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>U3NKNFLNQ613</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>748400</Code>
<Text>IIS Special Projects</Text>
</ProgramElement>
<ProgramElement>
<Code>801300</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002324DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~860188</FUND_OBLG>
<FUND_OBLG>2021~16000</FUND_OBLG>
<FUND_OBLG>2023~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our project had four high-level objectives:</p> <p>&nbsp;</p> <p><strong><span style="text-decoration: underline;">Objective 1 - Estimate the position and future motions of multiple targets with a team of flying robots (Primary)</span></strong></p> <p>A new study of methods for precise, rapid, and robust target motion forecasting and relative state estimation that estimates the 3D motion of the robots and actors quickly with strong uncertainty estimates.</p> <p><strong><span style="text-decoration: underline;">Objective 2 - Coordinate the collective robot motion to cover the area of interest</span></strong></p> <p>A new decomposition of the perception-aware multi-objective multi-UAV safe motion planning problem, that allows long-term planning based on consistent actor motion forecast uncertainty models and coverage objectives.</p> <p><strong><span style="text-decoration: underline;">Objective 3 - Guarantee robot safety, despite large disturbances and dynamics changes (Primary)</span></strong></p> <p>A new guaranteed safe, real-time adaptive paradigm for reactive flight control that is able to guarantee safety even with large disturbances and dynamics changes, and that can leverage prior simulated or real flight experience for quick adaptation.</p> <p><strong><span style="text-decoration: underline;">Objective 4 - Reconstruct a 3D spatio-temporal model of subjects using the multiview videos</span></strong></p> <p>A new theory of 3D multi-view reconstruction of a dynamic scene from moving onboard cameras that will enable high-resolution 3D dense and skeletal scene reconstruction.</p> <p>Objectives 1 and 2 are the primary focus for PIs Kitani and Scherer (CMU) respectively while the remaining two are the primary purview of our collaborators at University of Minnesota. However, PIs each also made contributions to the rest of the 4 objectives in varying degrees.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>Along each of the objectives of the project we had the following outcomes:</p> <p>&nbsp;</p> <p><strong>Objective 1: Target Detection, Tracking and Motion Forecasting</strong></p> <p>&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Kitani:&nbsp;</strong>We built a tracking-by-detection framework for fast and accurate dynamic target tracking. The detection is tuned to be capable for tiny and crowded target detection and the tracking is robust to complicated motion patterns.</p> <p>&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Kitani:&nbsp;</strong>Development of a method for multi-human 3D pose estimation from multiple camera views without knowing the camera poses</p> <p>&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Kitani:&nbsp;</strong>Deployment of detector + tracker on edge device. It provides good performance for general tracking but suffers from bad identification consistency when the target objects have several overlapping.<strong>&nbsp;</strong></p> <p><strong>Objective 2: Perception-aware Multi-robot Planning</strong></p> <p>&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Scherer:&nbsp;</strong>We have developed a view planning approach that can coordinate groups of robots to observe moving actors in scenes with various degrees of occupancy and occlusion. Our approach is capable of planning to view groups that split, join, and reorganize due to direct optimization of paths and views.</p> <p><strong>Objective 3: Robot coordination and safety</strong></p> <p>&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Scherer:&nbsp;</strong>We have developed a view planning approach for planning views for multiple robots observing groups of moving actors in scenarios featuring significant inter-robot conflicts (e.g. collisions) such as due to confined spaces, bottlenecks, or corridors.<strong>&nbsp;</strong></p> <p>&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Scherer:&nbsp;</strong>Toward development of a system for aerial filming and multi-person tracking</p> <p>&#9675;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Development of tracking backpacks for actors/targets based on RTK-GPS</p> <p>&#9675;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mapping field test site to enable collision-free operation based on RTK-GPS</p> <p>&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Scherer:&nbsp;</strong>Development of safe real-time multi-robot coordination scheme for 3d skeletal reconstruction amongst obstacles<strong>&nbsp;</strong></p> <p><strong>Objective 4: 3D Reconstruction of Dynamic Scenes</strong></p> <p>&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Kitani:&nbsp;</strong>We develop a multi-view multi-person 3D human pose estimation method that does not require extrinsically calibrated camera parameters or 3D human pose labels.</p> <p>&nbsp;</p><br> <p>  Last Modified: 10/14/2024<br> Modified by: Sebastian&nbsp;Scherer</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Our project had four high-level objectives:      Objective 1 - Estimate the position and future motions of multiple targets with a team of flying robots (Primary)   A new study of methods for precise, rapid, and robust target motion forecasting and relative state estimation that estimates the 3D motion of the robots and actors quickly with strong uncertainty estimates.   Objective 2 - Coordinate the collective robot motion to cover the area of interest   A new decomposition of the perception-aware multi-objective multi-UAV safe motion planning problem, that allows long-term planning based on consistent actor motion forecast uncertainty models and coverage objectives.   Objective 3 - Guarantee robot safety, despite large disturbances and dynamics changes (Primary)   A new guaranteed safe, real-time adaptive paradigm for reactive flight control that is able to guarantee safety even with large disturbances and dynamics changes, and that can leverage prior simulated or real flight experience for quick adaptation.   Objective 4 - Reconstruct a 3D spatio-temporal model of subjects using the multiview videos   A new theory of 3D multi-view reconstruction of a dynamic scene from moving onboard cameras that will enable high-resolution 3D dense and skeletal scene reconstruction.   Objectives 1 and 2 are the primary focus for PIs Kitani and Scherer (CMU) respectively while the remaining two are the primary purview of our collaborators at University of Minnesota. However, PIs each also made contributions to the rest of the 4 objectives in varying degrees.         Along each of the objectives of the project we had the following outcomes:      Objective 1: Target Detection, Tracking and Motion Forecasting   &#9679;Kitani:We built a tracking-by-detection framework for fast and accurate dynamic target tracking. The detection is tuned to be capable for tiny and crowded target detection and the tracking is robust to complicated motion patterns.   &#9679;Kitani:Development of a method for multi-human 3D pose estimation from multiple camera views without knowing the camera poses   &#9679;Kitani:Deployment of detector + tracker on edge device. It provides good performance for general tracking but suffers from bad identification consistency when the target objects have several overlapping.   Objective 2: Perception-aware Multi-robot Planning   &#9679;Scherer:We have developed a view planning approach that can coordinate groups of robots to observe moving actors in scenes with various degrees of occupancy and occlusion. Our approach is capable of planning to view groups that split, join, and reorganize due to direct optimization of paths and views.   Objective 3: Robot coordination and safety   &#9679;Scherer:We have developed a view planning approach for planning views for multiple robots observing groups of moving actors in scenarios featuring significant inter-robot conflicts (e.g. collisions) such as due to confined spaces, bottlenecks, or corridors.   &#9679;Scherer:Toward development of a system for aerial filming and multi-person tracking   &#9675;Development of tracking backpacks for actors/targets based on RTK-GPS   &#9675;Mapping field test site to enable collision-free operation based on RTK-GPS   &#9679;Scherer:Development of safe real-time multi-robot coordination scheme for 3d skeletal reconstruction amongst obstacles   Objective 4: 3D Reconstruction of Dynamic Scenes   &#9679;Kitani:We develop a multi-view multi-person 3D human pose estimation method that does not require extrinsically calibrated camera parameters or 3D human pose labels.        Last Modified: 10/14/2024       Submitted by: SebastianScherer]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
