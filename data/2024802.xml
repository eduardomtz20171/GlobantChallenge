<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: NRI: INT: Transparent and Intuitive Teleoperation Interfaces for the Future Nursing Robots and Workers]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>731329.00</AwardTotalIntnAmount>
<AwardAmount>731329</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
<PO_EMAI>wnilsen@nsf.gov</PO_EMAI>
<PO_PHON>7032922568</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The recent pandemic outbreaks, including Ebola, Zika and the 2019 Novel Coronavirus (2019-nCoV), urge tele-medicine to go beyond mere tele-presence, to achieve robots that perform real-world nursing assistance tasks that require the coordinated control of manipulation, locomotion, and active teleoperation. Remotely-controlled nursing robots provide a promising alternative for quarantine and remote patient care. However, the traditional and contemporary human-robot interfaces fundamentally limit the performance and user experience of nursing robot teleoperation, and may reinforce burden and safety concerns that discourage healthcare workers to adopt robots. To address this problem, this project will (1) develop an innovative integration of transparent and intuitive teleoperation interface, to support the freeform and coordinated motion control of the remote nursing robots, and (2) integrate this interface with the robot intelligence to enable nursing professionals to learn robot teleoperation with minimal training, and to reduce the physical and cognitive workload using shared autonomy. The proposed project will promote the progress of science in human-robot interfaces for robot teleoperation, and advance the quality, availability and sustainability of healthcare in the present and future pandemic crisis. This project will have significant impacts on the domain of nursing, which consists of 2.9 million registered nurses and 160,000 nurse practitioners across the U.S. It will revolutionize patient-care in quarantine, and has the potential to extend to in-home care, clinics, and hospitals given the upcoming shortage of nursing workforce. The fundamental research also generalizes to other worker domains with robot tele-operations, including warehouse, social service, and maintenance. The proposed research will forge substantial collaboration among faculty and students in robotics engineering, nursing and social science. &lt;br/&gt;&lt;br/&gt;This project consists of two research themes. Research Theme 1 will develop a soft-robot teleoperation interface architecture and systematic human-inspired motion mapping strategies, to support the intuitive and transparent mapping of the motion, force, and perception information between humans and robots. The proposed interface will enable transparent and legible robot behavior of reaching-to-grasp, loco-manipulation, and the control of active telepresence. Research Theme 2 will develop the intelligence of the interface, to enable interactive learning and mutual adaptation between humans and robots. Based on game-theoretic planning, it will develop adaptive shared autonomous strategies that use human-robot communication via haptic feedback. It will employ active tele-presence to enhance the training and reduce workload in tele-operation of the human operator. The integrated interface will be evaluated in comprehensive user studies with registered nurses, nursing faculty and nursing students. The evaluation will assess the performance and user experience, including human-robot teaming, using efficiency, workload and interface effort metrics. It will also evaluate the social impacts of the proposed human-robot interface on the acceptance and adoption of nursing robots by the current and future nursing workforce. &lt;br/&gt;&lt;br/&gt;This proposal was funded with the National Institute for Occupational Safety and Health (NIOSH) in the Center for Disease Control and Prevention (CDC).&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/19/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/05/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2024802</AwardID>
<Investigator>
<FirstName>Jeanine</FirstName>
<LastName>Skorinko</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeanine L Skorinko</PI_FULL_NAME>
<EmailAddress><![CDATA[skorinko@wpi.edu]]></EmailAddress>
<NSF_ID>000176857</NSF_ID>
<StartDate>08/19/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yunus</FirstName>
<LastName>Telliel</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yunus D Telliel</PI_FULL_NAME>
<EmailAddress><![CDATA[ydtelliel@wpi.edu]]></EmailAddress>
<NSF_ID>000528816</NSF_ID>
<StartDate>08/19/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Cagdas</FirstName>
<LastName>Onal</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Cagdas D Onal</PI_FULL_NAME>
<EmailAddress><![CDATA[cdonal@wpi.edu]]></EmailAddress>
<NSF_ID>000637331</NSF_ID>
<StartDate>08/19/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jie</FirstName>
<LastName>Fu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jie Fu</PI_FULL_NAME>
<EmailAddress><![CDATA[fujie@ufl.edu]]></EmailAddress>
<NSF_ID>000724230</NSF_ID>
<StartDate>08/19/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Zhi</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zhi Li</PI_FULL_NAME>
<EmailAddress><![CDATA[zli11@wpi.edu]]></EmailAddress>
<NSF_ID>000753375</NSF_ID>
<StartDate>08/19/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Worcester Polytechnic Institute]]></Name>
<CityName>WORCESTER</CityName>
<ZipCode>016092280</ZipCode>
<PhoneNumber>5088315000</PhoneNumber>
<StreetAddress><![CDATA[100 INSTITUTE RD]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>HJNQME41NBU4</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>WORCESTER POLYTECHNIC INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Worcester Polytechnic Institute]]></Name>
<CityName>Worcester</CityName>
<StateCode>MA</StateCode>
<ZipCode>016092247</ZipCode>
<StreetAddress><![CDATA[100 Institute Rd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>U35800</Code>
<Text/>
</ProgramElement>
<ProgramElement>
<Code>V23300</Code>
<Text/>
</ProgramElement>
<ProgramElement>
<Code>W21500</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002122RB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002021RB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002223RB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~245336</FUND_OBLG>
<FUND_OBLG>2021~245328</FUND_OBLG>
<FUND_OBLG>2022~240665</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-b740e20c-7fff-c77b-79b3-79a001252710">  <p dir="ltr"><span>Through this project we developed and evaluated integrative and intelligent human-robot interfaces which can effectively reduce the workload and learning efforts of operators novice to remote robot operation, so that they can easily and intuitively control mobile humanoid robots for nursing assistance tasks. These interfaces include: 1) a soft robotic glove &ndash; a wearable interface that can provide intuitive force and contact feedback in the control of dexterous robotic manipulation using multi-finger robot gripper; 2) a human-to-robot motion mapping interface for intuitive and effortless tele-manipulation control, which provides humans adaptive perception assistance (through haptic and augmented reality visual cues) and adaptive action assistance (through autonomous primitive actions and motion constraints) based on human&rsquo;s manipulation intents; 3) a novel human-robot interface for multimodal multilateral human-robot collaboration that enables multiple remote and local human nurses to collaborative supervise and assist autonomous nursing robots and enhances the human-human/human-robot collaboration through augmented reality and verbal communication.</span></p>  <br />  <p dir="ltr"><span>As for its engineering contribution, we developed novel prototypes of nursing robot platforms and interfaces, as well as the first open-source nursing robot virtual testbed. As for its theoretical contributions, our project investigated how to leverage multimodal feedback to mediate the interactive learning between humans and robot autonomy, and develop principled methods for preference learning in order to provide user-adaptive assistive teleoperation interfaces.&nbsp;&nbsp;</span></p>  <br />  <p dir="ltr"><span>Our convergent research efforts evaluated the usability of the tele-nursing robot interfaces and social impacts of tele-nursing robot technologies on nursing workers, educators and students. Our project achieved synergistic interdisciplinary research and education collaboration between robotics, social science and nursing.&nbsp;</span></p>  <div><span><br /></span></div>  </span></p>  <p>&nbsp;</p><br> <p>  Last Modified: 12/05/2024<br> Modified by: Zhi&nbsp;Li</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[      Through this project we developed and evaluated integrative and intelligent human-robot interfaces which can effectively reduce the workload and learning efforts of operators novice to remote robot operation, so that they can easily and intuitively control mobile humanoid robots for nursing assistance tasks. These interfaces include: 1) a soft robotic glove  a wearable interface that can provide intuitive force and contact feedback in the control of dexterous robotic manipulation using multi-finger robot gripper; 2) a human-to-robot motion mapping interface for intuitive and effortless tele-manipulation control, which provides humans adaptive perception assistance (through haptic and augmented reality visual cues) and adaptive action assistance (through autonomous primitive actions and motion constraints) based on humans manipulation intents; 3) a novel human-robot interface for multimodal multilateral human-robot collaboration that enables multiple remote and local human nurses to collaborative supervise and assist autonomous nursing robots and enhances the human-human/human-robot collaboration through augmented reality and verbal communication.       As for its engineering contribution, we developed novel prototypes of nursing robot platforms and interfaces, as well as the first open-source nursing robot virtual testbed. As for its theoretical contributions, our project investigated how to leverage multimodal feedback to mediate the interactive learning between humans and robot autonomy, and develop principled methods for preference learning in order to provide user-adaptive assistive teleoperation interfaces.       Our convergent research efforts evaluated the usability of the tele-nursing robot interfaces and social impacts of tele-nursing robot technologies on nursing workers, educators and students. Our project achieved synergistic interdisciplinary research and education collaboration between robotics, social science and nursing.              Last Modified: 12/05/2024       Submitted by: ZhiLi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
