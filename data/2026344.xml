<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Conformable systems for spatiotemporal decoding of facial strains]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>349997.00</AwardTotalIntnAmount>
<AwardAmount>349997</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Svetlana Tatic-Lucic</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Many neuromuscular disorders, such as amyotrophic lateral sclerosis (ALS), often manifest themselves through physiological changes including gradual loss of the ability to exercise fine motor skills and to vocalize intelligible speech. Predictable methods for continuous tracking of dynamic skin strain on the face, therefore, can enable new forms of communication for individuals with such disorders. Present methods for in vivo characterization of facial deformations involve electromyography (EMG), skin impedance measurements, or camera tracking. Yet these typically result in high uncertainties or have bulky structures with highly visible interfaces to soft skin, presenting difficulty for continuous use in daily life, especially for individuals with neuromuscular disorders. The aim of the proposed research is to realize conformable sensors and systems that can translate patterns of facial soft tissue biomechanics in vivo into interpretable electrical signals to enable new forms of non-verbal communication. The concepts, materials, system design and characterization methods to be introduced in this project can offer new routes for rapid, in vivo biokinematic assessment of epidermal surfaces during dynamic movements. Such systems can help for continuous clinical monitoring of a wide range of neuromuscular conditions, where variations are anticipated due either to (i) time-dependent alterations in muscle movements, and thus measurable epidermal deformations due to neurodegeneration progression, or (ii) a response throughout medical therapy. The proposed interdisciplinary project will be integrated with educational and outreach activities, including interdisciplinary classes on the microfabrication of conformable sensors and the development of lower-power, computationally light paradigms for medical sensing for underrepresented students all the way from K-12 to graduate levels.&lt;br/&gt;&lt;br/&gt;Precise measurements of soft tissue biokinematics, such as skin strain during facial deformations, can be used to computationally recognize distinct facial motions, and thus facilitate nonverbal communication for patients who lack the ability to speak or interact with traditional electronic communication interfaces. However, existing nonverbal communication systems are unsuitable for use on curvilinear regions of the body, such as the face. A widely deployable system for real-time detection of facial motions, when combined with the use of low-cost materials, easily manufacturable processes, and a seamless pipeline for fabrication, testing, and validation, offers unprecedented potential for clinically realizable nonverbal communication technologies. The primary goal of the proposed research is to introduce a set of materials, device designs, fabrication steps, theoretical calculations, simulations, and validation protocols that realize robust, mechanically-adaptive, predictable, and visually-invisible in vivo monitoring of spatiotemporal epidermal strains and decoding of distinct facial deformation signatures through the use of conformable devices comprised of piezoelectric thin films on compliant substrates. The challenges that will be addressed during the course of the project include: 1) Development of a conformable Facial Code Extrapolation Sensor (cFaCES), 2) Three-Dimensional Digital Image Correlation (3D-DIC) for spatiotemporal assessment of soft tissues under dynamic deformations, and 3) In vivo Real-Time Decoding (RTD) on both healthy and amyotrophic lateral sclerosis (ALS) subjects during various facial deformations. The proposed work will build upon the PI's interdisciplinary expertise and experience in piezoelectric, microfabricated biomedical devices and conformable systems. The proposed system will introduce a novel device design and microfabrication strategy, along with a framework and advanced algorithms that will be a key enabler to reconstruct spatiotemporally accurate strain maps for any human body soft tissue.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/11/2020</MinAmdLetterDate>
<MaxAmdLetterDate>08/11/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2026344</AwardID>
<Investigator>
<FirstName>Canan</FirstName>
<LastName>Dagdeviren</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Canan Dagdeviren</PI_FULL_NAME>
<EmailAddress><![CDATA[canand@mit.edu]]></EmailAddress>
<NSF_ID>000804689</NSF_ID>
<StartDate>08/11/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>CAMBRIDGE</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress><![CDATA[77 MASSACHUSETTS AVE]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>E2NYLCDML6V1</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>E2NYLCDML6V1</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021344307</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>756400</Code>
<Text>CCSS-Comms Circuits &amp; Sens Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>090E</Code>
<Text>Chem/Bio and Physical Diagnostics</Text>
</ProgramReference>
<ProgramReference>
<Code>104E</Code>
<Text>MEMS/NEMS</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~349997</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Communication by people with neuromuscular disorders, such as those with amyotrophic lateral sclerosis (ALS), relies on assistive devices that strive to continuously track dynamic facial and eye movements. Despite best efforts, present methods are typically inaccurate, slow, or bulky, presenting difficulty for continuous use in daily life. With cFaCES (conformable Facial Code Extrapolation Sensor), our mission was to develop conformable piezoelectric sensors and systems that translate patterns of facial soft tissue biomechanics in vivo into interpretable electrical signals to enable new forms of non-verbal communication. Our device contains aluminum nitride (AlN) piezoelectric thin films on compliant polydimethylsiloxane (PDMS) substrates, along with a closed-loop framework that predicts and validates the conformable sensor&rsquo;s ability to capture readings and epidermal motions of interest. This innovative work bridges these four fields for the first time: conformable decoding, three-dimensional digital image correlation (3D-DIC), compressed sensing, and machine learning. At only $10 per device, the cFaCES is the first non-verbal communication system with three orders of magnitude lower computational load than current methods, such as EEG or camera tracking, attributed to 3D-DIC-supported device design.</p> <p>The major goals of the project were: 1) to introduce a set of materials, device designs, fabrication steps, theoretical calculations, simulations, and validation<br />protocols that realize robust, mechanically-adaptive, predictable, and visually-invisible devices for in vivo monitoring of spatiotemporal epidermal strains for non-verbal communication, 2) to decode distinct facial deformation signatures through the use of conformable devices &mdash; comprised of aluminum nitride (AlN) piezoelectric thin films on compliant polydimethylsiloxane (PDMS) substrates &mdash; along with a closed-loop framework that predicts and validates the conformable sensor&rsquo;s ability to capture readings and epidermal motions of interest, 3) to present a novel methodology that enables closed-loop voltage-strain correlation in mechanically adaptive, piezoelectric devices that informs sensor placement by quantitative study of dynamic soft tissue biokinematics using stereophotogrammetry (PG) and subsequent three-dimensional digital image correlation (3D-DIC). While we achieved all of our above goals, comprehensive theoretical and in vitro experimental studies were conducted to provide accurate and reproducible measurements of strain during compression, stretching, and bending in quasi-static regimes. In vivo experiments on healthy and amyotrophic lateral sclerosis (ALS) subjects coupled with further theoretical studies and 3D-DIC assessment were demonstrated.</p><br> <p>  Last Modified: 11/30/2023<br> Modified by: Canan&nbsp;Dagdeviren</p></div> <div class="porSideCol" ><div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)          </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2023/2026344/2026344_10695414_1701372365442_IMG_0345--rgov-214x142.JPG" original="/por/images/Reports/POR/2023/2026344/2026344_10695414_1701372365442_IMG_0345--rgov-800width.JPG" title="cFaCES"><img src="/por/images/Reports/POR/2023/2026344/2026344_10695414_1701372365442_IMG_0345--rgov-66x44.JPG" alt="cFaCES"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our cFaCES on a glass ware</div> <div class="imageCredit">Canan Dagdeviren</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Canan&nbsp;Dagdeviren <div class="imageTitle">cFaCES</div> </div> </li><li> <a href="/por/images/Reports/POR/2023/2026344/2026344_10695414_1701372458700_6--rgov-214x142.jpg" original="/por/images/Reports/POR/2023/2026344/2026344_10695414_1701372458700_6--rgov-800width.jpg" title="cFaCES on a healthy subject"><img src="/por/images/Reports/POR/2023/2026344/2026344_10695414_1701372458700_6--rgov-66x44.jpg" alt="cFaCES on a healthy subject"></a> <div class="imageCaptionContainer"> <div class="imageCaption">cFaCES on a healthy subject</div> <div class="imageCredit">Canan Dagdeviren</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Canan&nbsp;Dagdeviren <div class="imageTitle">cFaCES on a healthy subject</div> </div> </li></ul> </div> </div></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Communication by people with neuromuscular disorders, such as those with amyotrophic lateral sclerosis (ALS), relies on assistive devices that strive to continuously track dynamic facial and eye movements. Despite best efforts, present methods are typically inaccurate, slow, or bulky, presenting difficulty for continuous use in daily life. With cFaCES (conformable Facial Code Extrapolation Sensor), our mission was to develop conformable piezoelectric sensors and systems that translate patterns of facial soft tissue biomechanics in vivo into interpretable electrical signals to enable new forms of non-verbal communication. Our device contains aluminum nitride (AlN) piezoelectric thin films on compliant polydimethylsiloxane (PDMS) substrates, along with a closed-loop framework that predicts and validates the conformable sensors ability to capture readings and epidermal motions of interest. This innovative work bridges these four fields for the first time: conformable decoding, three-dimensional digital image correlation (3D-DIC), compressed sensing, and machine learning. At only $10 per device, the cFaCES is the first non-verbal communication system with three orders of magnitude lower computational load than current methods, such as EEG or camera tracking, attributed to 3D-DIC-supported device design.   The major goals of the project were: 1) to introduce a set of materials, device designs, fabrication steps, theoretical calculations, simulations, and validation protocols that realize robust, mechanically-adaptive, predictable, and visually-invisible devices for in vivo monitoring of spatiotemporal epidermal strains for non-verbal communication, 2) to decode distinct facial deformation signatures through the use of conformable devices  comprised of aluminum nitride (AlN) piezoelectric thin films on compliant polydimethylsiloxane (PDMS) substrates  along with a closed-loop framework that predicts and validates the conformable sensors ability to capture readings and epidermal motions of interest, 3) to present a novel methodology that enables closed-loop voltage-strain correlation in mechanically adaptive, piezoelectric devices that informs sensor placement by quantitative study of dynamic soft tissue biokinematics using stereophotogrammetry (PG) and subsequent three-dimensional digital image correlation (3D-DIC). While we achieved all of our above goals, comprehensive theoretical and in vitro experimental studies were conducted to provide accurate and reproducible measurements of strain during compression, stretching, and bending in quasi-static regimes. In vivo experiments on healthy and amyotrophic lateral sclerosis (ALS) subjects coupled with further theoretical studies and 3D-DIC assessment were demonstrated.     Last Modified: 11/30/2023       Submitted by: CananDagdeviren]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
