<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: CPS: Medium: Empowering prosumers in electricity markets through market design and learning]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Aranya Chakrabortty</SignBlockName>
<PO_EMAI>achakrab@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The availability of vast amounts of operational and end-user data in cyber-physical systems implies that paradigm improvements in monitoring and control can be attained via learning by many artificial intelligence agents despite them possessing vastly different abilities.  Engaging this heterogeneous agent base in the context of the smart grid requires the use of hierarchical markets, wherein end-users participate in downstream markets collectively through aggregators, who in turn are coordinated by an upstream market.  The goal of this project is to conduct a systematic study of such market-mediated learning and control.   This project aims at much deeper levels of participation from end-users contributing electricity generation such as rooftop solar, shedding load via demand response, and providing storage capabilities such as electric vehicle batteries, to transform into reliable distributed energy resources (DER) at the level of wholesale markets.  A methodological theme is multi-agent reinforcement learning (MARL) by agents that control physical systems via actions at different levels of the hierarchy.  Underlying the whole project are well-founded physical models of the transmission and distribution grids, which provide structure to the problem domain and concrete use cases.  This project facilitates a deeper level of decarbonization in the electricity sector, and contributes to climate change solutions by engineering a flat, interactive grid architecture that allows significant DERs to provide electricity services to both local and regional grids.  Engagement with a grid-level market operator enables the project to address a problem space of immediate relevance to the current electricity grid.  The project also includes the development of educational materials on data-analytics and energy systems.  Intrinsic to the program are efforts at outreach to involve high-school students via demonstrations and lectures based on the technology developed.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;The goal of this project is a systematic and principled study of methods for hierarchical market-mediated learning and control, with the electric grid being the primary application domain.  Multi-agent reinforcement learning (MARL) runs as a common methodological theme through the project, with strategic agents with varying information structures and concepts of rationality that control physical systems via actions at different levels of the hierarchy.  The approach is different from studies on generic MARL algorithms in that attention is focused on well-founded physical models of the transmission and distribution grids, as well as the workings of the power system.  The project is organized into three interdependent thrusts, namely, (i) Learning to bid as aggregators in wholesale markets, which studies dynamics of aggregators that provide supply offers and demand bids at the upstream market (wholesale level), while procuring these services from downstream DERs (retail level), (ii) Learning to incentivize retail users to contribute their resources, under which bounded rational agents learn to respond to a population-level distribution of other agents and incentives provided, and (iii) Evaluation and experimentation over a full-scale system emulator by integrating it with reinforcement learning tools.  This project provides an architecture for DERs to provide electricity services to both local and regional grids, and hence contributes to developing solutions to climate change.  Engagement with an independent system operator enables a focus on grid-specific issues, ensuring the applicability of the solutions to real-world problems.  The impact is enhanced by specific minority inclusion activities, courses on computing tailored to broaden participation in the context of data-analytics and energy systems, and outreach to high-school students using demonstrations and lectures based on the project results.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/02/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/14/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2038416</AwardID>
<Investigator>
<FirstName>Vijay</FirstName>
<LastName>Subramanian</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vijay G Subramanian</PI_FULL_NAME>
<EmailAddress><![CDATA[vgsubram@umich.edu]]></EmailAddress>
<NSF_ID>000610770</NSF_ID>
<StartDate>09/02/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Regents of the University of Michigan - Ann Arbor]]></Name>
<CityName>ANN ARBOR</CityName>
<ZipCode>481091079</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress><![CDATA[1109 GEDDES AVE, SUITE 3300]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI06</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>GNJ7BBP73WE9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Regents of the University of Michigan - Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481092122</ZipCode>
<StreetAddress><![CDATA[1301 Beal Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>791800</Code>
<Text>CPS-Cyber-Physical Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>155E</Code>
<Text>Electric power networks</Text>
</ProgramReference>
<ProgramReference>
<Code>1653</Code>
<Text>Adaptive &amp; intelligent systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1">The goal of this project is to conduct a systematic study of data-driven learning and control in multi-agent systems, many of which are market-mediated such as smart grids. A methodological theme is multi-agent reinforcement learning (MARL) by agents that control physical systems via actions at different levels of the hierarchy. As complex models apply in modern socio-technological systems, making foundational advances in single-agent reinforcement learning (RL) was also part of the methodologcal theme.</p>  <!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 5.0px Arial; color: #000000} -->  <p style="caret-color: #000000; color: #000000; font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none;">We took a broad perspective so that the developed methods could be used in many contexts. Here we considered several aspects that arise in application domains such as smart grid (transmission and distribution grids), communication netoworks and networking systems, and multi-agent systems, in general. The aspects we concentrated on were: 1) complex stochastic dynamics; 2) countable state-spaces; 3) sampling-based measurements of systems for decision-making; 4) multi-agents aspects like information asymmetry, achieving scalability, and strategic behavior; 5) constraints on operation arising from power limitations or safety.&nbsp;&nbsp;</p>  <p style="caret-color: #000000; color: #000000; font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none;">Our findings can be broadly summarized as follows:</p>  <ol style="caret-color: #000000; color: #000000; font-family: Helvetica; font-size: 12px; font-style: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; text-decoration: none;">  <li>Information state based RL algorithms for multi-agent systems: A key step in being able to develop RL algorithms with provable performance guarantees for the unknown model setting in decentralized multi-agent teams is to characterize an approximate information state that is not only sufficient for a dynamic programming but also has good regret (to control sub-optimality of the control policies developed). For a large class of multi-agent teams, we provided a direct characterization of an information state that allows for optimal solutions---these were studied for decentralized dynamic teams with and without constraints, dynamic games, and dynamic games of teams. For dynamic games and games of teams, we developed strategy independent information states, and showed the strategy dependent information states can be problematic. As the information state may also grow with time, this framework then was used to study when a good time-invariant approximate information state can be developed.&nbsp;</li>  <li>Learning-based optimal control of queueing system models of communication networks: Optimal control in many systems, particularly continuous-time queueing systems, is not easily amenable to reinforcement learning (RL) methods owing to the lack of dense reward signals and due to complex structures inherent in these system. Using model-class knowledge, however, information rewards (to predict the data generated) are available. Using these alternate signals, we explored the design of optimal controls. We studied three problems in this context: 1) optimal admission control to an Erlang-blocking system with unknown service rate and holding cost; 2) optimal admission control to a single-server with unknown service rate and holding cost; and 3) parametric countable state controlled Markov chains. For these we developed low-regret learning-based optimal control algorithms using either a perturbed maximum-likelihood estimate or Thompson sampling.</li>  <li>Learning-based optimal control of multi-agent systems with applications to networking systems: Building on our information-state work, we studied algorithms for cooperative systems with multiple-agents with the goal to develop optimal control methodologies in a data-driven manner. Within this topic we also looked at a decentralized multi-agent formulation for wireless media streaming. This involved the development of learning-based control for partially observed Markov decision processes with constraints. In the wireless media streaming problem feedback delays creates information asymmetry and a decentralized team control problem. We have developed a decentralized team formulation and planning solution. We developed a general result for control of such decentralized team systems with joint constraints, and applied that to the video-streaming problem to develop not only scalable optimal algorithms but learning-based solutions.</li>  </ol><br> <p>  Last Modified: 12/26/2024<br> Modified by: Vijay&nbsp;G&nbsp;Subramanian</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  The goal of this project is to conduct a systematic study of data-driven learning and control in multi-agent systems, many of which are market-mediated such as smart grids. A methodological theme is multi-agent reinforcement learning (MARL) by agents that control physical systems via actions at different levels of the hierarchy. As complex models apply in modern socio-technological systems, making foundational advances in single-agent reinforcement learning (RL) was also part of the methodologcal theme.      We took a broad perspective so that the developed methods could be used in many contexts. Here we considered several aspects that arise in application domains such as smart grid (transmission and distribution grids), communication netoworks and networking systems, and multi-agent systems, in general. The aspects we concentrated on were: 1) complex stochastic dynamics; 2) countable state-spaces; 3) sampling-based measurements of systems for decision-making; 4) multi-agents aspects like information asymmetry, achieving scalability, and strategic behavior; 5) constraints on operation arising from power limitations or safety.    Our findings can be broadly summarized as follows:    Information state based RL algorithms for multi-agent systems: A key step in being able to develop RL algorithms with provable performance guarantees for the unknown model setting in decentralized multi-agent teams is to characterize an approximate information state that is not only sufficient for a dynamic programming but also has good regret (to control sub-optimality of the control policies developed). For a large class of multi-agent teams, we provided a direct characterization of an information state that allows for optimal solutions---these were studied for decentralized dynamic teams with and without constraints, dynamic games, and dynamic games of teams. For dynamic games and games of teams, we developed strategy independent information states, and showed the strategy dependent information states can be problematic. As the information state may also grow with time, this framework then was used to study when a good time-invariant approximate information state can be developed.  Learning-based optimal control of queueing system models of communication networks: Optimal control in many systems, particularly continuous-time queueing systems, is not easily amenable to reinforcement learning (RL) methods owing to the lack of dense reward signals and due to complex structures inherent in these system. Using model-class knowledge, however, information rewards (to predict the data generated) are available. Using these alternate signals, we explored the design of optimal controls. We studied three problems in this context: 1) optimal admission control to an Erlang-blocking system with unknown service rate and holding cost; 2) optimal admission control to a single-server with unknown service rate and holding cost; and 3) parametric countable state controlled Markov chains. For these we developed low-regret learning-based optimal control algorithms using either a perturbed maximum-likelihood estimate or Thompson sampling.  Learning-based optimal control of multi-agent systems with applications to networking systems: Building on our information-state work, we studied algorithms for cooperative systems with multiple-agents with the goal to develop optimal control methodologies in a data-driven manner. Within this topic we also looked at a decentralized multi-agent formulation for wireless media streaming. This involved the development of learning-based control for partially observed Markov decision processes with constraints. In the wireless media streaming problem feedback delays creates information asymmetry and a decentralized team control problem. We have developed a decentralized team formulation and planning solution. We developed a general result for control of such decentralized team systems with joint constraints, and applied that to the video-streaming problem to develop not only scalable optimal algorithms but learning-based solutions.       Last Modified: 12/26/2024       Submitted by: VijayGSubramanian]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
