<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[SaTC: CORE: Medium: Collaborative: Rethinking Access Pattern Privacy: From Theory to Practice]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>254891.00</AwardTotalIntnAmount>
<AwardAmount>254891</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anna Squicciarini</SignBlockName>
<PO_EMAI>asquicci@nsf.gov</PO_EMAI>
<PO_PHON>7032925177</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When a program accesses data stored in memory, disk, or on a remote server, its access patterns can leak information about its secret inputs and data. There has been decades of work that investigated how to prevent programs from leaking any information by making their access patterns "oblivious", i.e., independent from their execution. This project is motivated by the significant overhead that past techniques incur. The project introduces and investigates new relaxed notions of access pattern obliviousness, and discovers new algorithms that achieve these notions with a significantly reduced overhead. The project includes training of Ph.D. students and postdoctoral researchers, and mentoring activities focused on high school, undergraduate, and graduate students. &lt;br/&gt;&lt;br/&gt;This project rethinks the definition of access pattern privacy, and considers (but not limited to) a new notion called "differential obliviousness". In analogy with differential privacy, differential obliviosness requires that the access patterns resulting from executing a program on similar inputs should be hard to distinguish. The project establishes theoretical understanding, including new lower and upper bounds, of the extent to which various notions of obliviosness impact the performance of programs. The investigators also explore the practical performance of new privacy-preserving algorithms in cloud outsourcing and database scenarios. The project develops open-source libraries for the new, differentially oblivious algorithms and data structures.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/21/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/15/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2001041</AwardID>
<Investigator>
<FirstName>Yaacov</FirstName>
<LastName>Nissim Kobliner</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yaacov Nissim Kobliner</PI_FULL_NAME>
<EmailAddress><![CDATA[kobbi.nissim@georgetown.edu]]></EmailAddress>
<NSF_ID>000701169</NSF_ID>
<StartDate>08/21/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Georgetown University]]></Name>
<CityName>WASHINGTON</CityName>
<ZipCode>200570001</ZipCode>
<PhoneNumber>2026250100</PhoneNumber>
<StreetAddress><![CDATA[MAIN CAMPUS]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<StateCode>DC</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DC00</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>TF2CMKY1HMX9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>GEORGETOWN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>TF2CMKY1HMX9</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgetown University]]></Name>
<CityName>Washington</CityName>
<StateCode>DC</StateCode>
<ZipCode>200571789</ZipCode>
<StreetAddress><![CDATA[37th and O St., N.W.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DC00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>806000</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~254891</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="container-fluid"> <div class="col"><strong><span style="font-size: 1em;">Major results at the last year of the award:</span></strong></div> <div class="col"> <div class="container-fluid"> <div class="col"> <h4>1. Private Everlasting Prediction:&nbsp;<span style="font-size: 12px; font-weight: normal;">A private learner is trained on a sample of labeled points and generates a hypothesis that can be used for predicting the labels of newly sampled points while protecting the privacy of the training set. Past research uncovered that private learners exhibit significantly higher sample complexity than non-private learners.</span></h4> <h4><span style="font-size: 12px; font-weight: normal;">We explore <strong>prediction</strong> as an alternative to learning. A predictor answers a stream of classification queries instead of outputting a hypothesis. Earlier work on prediction has considered a model for answering a single classification query. </span></h4> <h4><span style="font-size: 12px; font-weight: normal;">We observe that when answering a stream of queries, a predictor must modify the hypothesis it uses over time, and in a manner that cannot rely solely on the training set. We introduce <strong>private everlasting prediction</strong>&nbsp;taking into account the privacy of both the training set and the (adaptively chosen) queries made to the predictor. We present a generic construction of private everlasting predictors in the PAC model.The sample complexity of the initial training sample in our construction is quadratic in the VC dimension of the concept class. Our construction allows prediction for all concept classes with finite VC dimension, and in particular threshold functions over infinite domains, for which private learning is known to be impossible.</span></h4> <p><span>Appeared in NeuRIPS 2023. Authors:&nbsp;</span><em style="font-size: 12px;">Moni Naor, Kobbi Nissim, Uri Stemmer, Chao Yan</em></p> <p>&nbsp;</p> <p><strong><span style="font-size: 1em;"><em>2.&nbsp;</em>Black-Box Differential Privacy for Interactive ML:&nbsp;</span></strong><span style="font-size: 12px;">We apply a variant of the privacy definition we developed for private everlasting prediction in the setting of online classification. We show that any (possibly non-private) learning rule can be effectively transformed to a private learning rule with only a polynomial overhead in the mistake bound. This demonstrates a stark difference with traditional forms of differential privacy, such as the one studied by Golowich and Livni [2021], where only a double exponential overhead in the mistake bound is known.</span></p> </div> </div> </div> <div class="col"> <p>Appeared in NeuRIPS 2023. Authors:&nbsp;<em style="font-size: 12px;">Haim Kaplan, Yishay Mansour, Shay Moran, Kobbi Nissim, Uri Stemmer</em></p> </div> <div class="col"><strong><span style="font-size: 1em;">3. Adaptive Data Analysis in a Balanced Adversarial Model: </span></strong><span style="font-size: 12px;">In adaptive data analysis, a mechanism gets&nbsp;</span><span id="MathJax-Element-1-Frame" class="mjx-chtml MathJax_CHTML" style="font-size: 12px;"><span id="MJXc-Node-1" class="mjx-math"><span id="MJXc-Node-2" class="mjx-mrow"><span id="MJXc-Node-3" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">n</span></span></span></span></span><span style="font-size: 12px;">&nbsp;i.i.d. samples from an unknown distribution&nbsp;</span><span id="MathJax-Element-2-Frame" class="mjx-chtml MathJax_CHTML" style="font-size: 12px;"><span id="MJXc-Node-4" class="mjx-math"><span id="MJXc-Node-5" class="mjx-mrow"><span id="MJXc-Node-6" class="mjx-texatom"><span id="MJXc-Node-7" class="mjx-mrow"><span id="MJXc-Node-8" class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R">D</span></span></span></span></span></span></span><span style="font-size: 12px;">, and is required to provide accurate estimations to a sequence of adaptively chosen statistical queries w.r.t.&nbsp;</span><span id="MathJax-Element-3-Frame" class="mjx-chtml MathJax_CHTML" style="font-size: 12px;"><span id="MJXc-Node-9" class="mjx-math"><span id="MJXc-Node-10" class="mjx-mrow"><span id="MJXc-Node-11" class="mjx-texatom"><span id="MJXc-Node-12" class="mjx-mrow"><span id="MJXc-Node-13" class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R">D</span></span></span></span></span></span></span><span style="font-size: 12px;">. Earlier work showed that in general, it is computationally hard to answer more than a quadratic number of</span><span style="font-size: 12px;">&nbsp;adaptive queries, assuming the existence of private-key cryptography. These results rely on an adversarial model that significantly advantages the adversarial analyst over the mechanism: the adversarial analyst, who chooses the adaptive queries, also chooses the underlying distribution&nbsp;</span><span id="MathJax-Element-5-Frame" class="mjx-chtml MathJax_CHTML" style="font-size: 12px;"><span id="MJXc-Node-22" class="mjx-math"><span id="MJXc-Node-23" class="mjx-mrow"><span id="MJXc-Node-24" class="mjx-texatom"><span id="MJXc-Node-25" class="mjx-mrow"><span id="MJXc-Node-26" class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R">D</span></span></span></span></span></span></span><span style="font-size: 12px;">. An</span><span style="font-size: 12px;">&nbsp;imbalance raises questions -- an analyst who has complete knowledge of the underlying distribution&nbsp;</span><span id="MathJax-Element-6-Frame" class="mjx-chtml MathJax_CHTML" style="font-size: 12px;"><span id="MJXc-Node-27" class="mjx-math"><span id="MJXc-Node-28" class="mjx-mrow"><span id="MJXc-Node-29" class="mjx-texatom"><span id="MJXc-Node-30" class="mjx-mrow"><span id="MJXc-Node-31" class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R">D&nbsp;</span></span></span></span></span></span></span><span style="font-size: 12px;">would have little need, if at all, to issue statistical queries to a mechanism which only holds a finite number of samples from&nbsp;</span><span id="MathJax-Element-7-Frame" class="mjx-chtml MathJax_CHTML" style="font-size: 12px;"><span id="MJXc-Node-32" class="mjx-math"><span id="MJXc-Node-33" class="mjx-mrow"><span id="MJXc-Node-34" class="mjx-texatom"><span id="MJXc-Node-35" class="mjx-mrow"><span id="MJXc-Node-36" class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R">D!</span></span></span></span></span></span></span></div> <div class="col"><span class="mjx-chtml MathJax_CHTML" style="font-size: 12px;"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-cal-R"><br /></span></span></span></span></span></span></span></div> <div class="col"><span style="font-size: 12px;">We consider balanced adversaries. These consist of two separated algorithms: a <strong>sampler</strong> that chooses the distribution and provides the samples to the mechanism, and an <strong>analyst </strong>who chooses the adaptive queries, but has no prior knowledge of the underlying distribution and hence no a priori advantage over the mechanism. We prove that the previous lower bounds hold also for balanced adversaries, under a standard public-key cryptography assumption. We also show that public-key assumptions are unavoidable in the sense that any computationally bounded balanced adversary that has the structure of all known attacks, implies the existence of public-key cryptography.</span></div> <div class="col"><span style="font-size: 12px;"><br /></span></div> </div> <p>Appeared in NeuRIPS 2023. Authors:&nbsp;<em style="font-size: 12px;">Kobbi Nissim, Uri Stemmer, Eliad Tsfadia</em></p> <p>&nbsp;</p><br> <p>  Last Modified: 03/17/2024<br> Modified by: Yaacov&nbsp;Nissim Kobliner</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Major results at the last year of the award:    1. Private Everlasting Prediction:A private learner is trained on a sample of labeled points and generates a hypothesis that can be used for predicting the labels of newly sampled points while protecting the privacy of the training set. Past research uncovered that private learners exhibit significantly higher sample complexity than non-private learners. We explore prediction as an alternative to learning. A predictor answers a stream of classification queries instead of outputting a hypothesis. Earlier work on prediction has considered a model for answering a single classification query.  We observe that when answering a stream of queries, a predictor must modify the hypothesis it uses over time, and in a manner that cannot rely solely on the training set. We introduce private everlasting predictiontaking into account the privacy of both the training set and the (adaptively chosen) queries made to the predictor. We present a generic construction of private everlasting predictors in the PAC model.The sample complexity of the initial training sample in our construction is quadratic in the VC dimension of the concept class. Our construction allows prediction for all concept classes with finite VC dimension, and in particular threshold functions over infinite domains, for which private learning is known to be impossible.   Appeared in NeuRIPS 2023. Authors:Moni Naor, Kobbi Nissim, Uri Stemmer, Chao Yan      2.Black-Box Differential Privacy for Interactive ML:We apply a variant of the privacy definition we developed for private everlasting prediction in the setting of online classification. We show that any (possibly non-private) learning rule can be effectively transformed to a private learning rule with only a polynomial overhead in the mistake bound. This demonstrates a stark difference with traditional forms of differential privacy, such as the one studied by Golowich and Livni [2021], where only a double exponential overhead in the mistake bound is known.       Appeared in NeuRIPS 2023. Authors:Haim Kaplan, Yishay Mansour, Shay Moran, Kobbi Nissim, Uri Stemmer  3. Adaptive Data Analysis in a Balanced Adversarial Model: In adaptive data analysis, a mechanism getsni.i.d. samples from an unknown distributionD, and is required to provide accurate estimations to a sequence of adaptively chosen statistical queries w.r.t.D. Earlier work showed that in general, it is computationally hard to answer more than a quadratic number ofadaptive queries, assuming the existence of private-key cryptography. These results rely on an adversarial model that significantly advantages the adversarial analyst over the mechanism: the adversarial analyst, who chooses the adaptive queries, also chooses the underlying distributionD. Animbalance raises questions -- an analyst who has complete knowledge of the underlying distributionDwould have little need, if at all, to issue statistical queries to a mechanism which only holds a finite number of samples fromD!   We consider balanced adversaries. These consist of two separated algorithms: a sampler that chooses the distribution and provides the samples to the mechanism, and an analyst who chooses the adaptive queries, but has no prior knowledge of the underlying distribution and hence no a priori advantage over the mechanism. We prove that the previous lower bounds hold also for balanced adversaries, under a standard public-key cryptography assumption. We also show that public-key assumptions are unavoidable in the sense that any computationally bounded balanced adversary that has the structure of all known attacks, implies the existence of public-key cryptography.      Appeared in NeuRIPS 2023. Authors:Kobbi Nissim, Uri Stemmer, Eliad Tsfadia        Last Modified: 03/17/2024       Submitted by: YaacovNissim Kobliner]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
