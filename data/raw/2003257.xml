<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[MLWiNS: RL-based Self-driving Wireless Network Management System for QoE Optimization]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2020</AwardEffectiveDate>
<AwardExpirationDate>07/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>560000.00</AwardTotalIntnAmount>
<AwardAmount>609599</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The proliferation of Internet-connected devices and applications, which are heavily reliant on high-speed, robust networks, have made the management of networks difficult and complicated. While the incorporation of programmable switches and machine-learning tools in data-centers and wide-area networks has contributed to improvements in Quality of Experience (QoE), access networks, which heavily rely on human operators for most network management tasks, remain the final frontier for providing a high quality of experience to end-users. The goal of this project is to design, implement, and evaluate RELIEF, a REinforcement-LearnIng (RL)-based sElF-driving wireless network-management system that can dynamically update network configurations to detect, diagnose, and resolve network events that contribute to QoE degradation. &lt;br/&gt;&lt;br/&gt;This project will develop new data-collection tools to capture fine-grained network data, new metrics to quantify QoE for the network, a scalable and explainable RL-based learning model to dynamically configure the underlying network and data-processing pipelines for QoE optimization. This project pursues fundamental contributions to the reinforcement learning area by developing novel solutions to inherent statistical and computational challenges. Finally, this project will design new programming abstractions and data structures to build an end-to-end system that optimizes the use of limited network resources to execute the trained RL models at scale.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/16/2020</MinAmdLetterDate>
<MaxAmdLetterDate>08/22/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2003257</AwardID>
<Investigator>
<FirstName>Elizabeth</FirstName>
<LastName>Belding</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Elizabeth M Belding</PI_FULL_NAME>
<EmailAddress><![CDATA[ebelding@cs.ucsb.edu]]></EmailAddress>
<NSF_ID>000264752</NSF_ID>
<StartDate>06/16/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Arpit</FirstName>
<LastName>Gupta</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Arpit Gupta</PI_FULL_NAME>
<EmailAddress><![CDATA[arpitgupta@cs.ucsb.edu]]></EmailAddress>
<NSF_ID>000784374</NSF_ID>
<StartDate>06/16/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yu-Xiang</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yu-Xiang Wang</PI_FULL_NAME>
<EmailAddress><![CDATA[yuxiangw@ucsd.edu]]></EmailAddress>
<NSF_ID>000785032</NSF_ID>
<StartDate>06/16/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[University of California-Santa Barbara]]></Name>
<CityName>SANTA BARBARA</CityName>
<ZipCode>931060001</ZipCode>
<PhoneNumber>8058934188</PhoneNumber>
<StreetAddress><![CDATA[3227 CHEADLE HALL]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA24</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>G9QBQDH39DF4</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SANTA BARBARA</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Santa Barbara]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>931065110</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA24</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>736300</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>021Z</Code>
<Text>Industry Partnerships</Text>
</ProgramReference>
<ProgramReference>
<Code>044Z</Code>
<Text>PAWR- Platforms for Advanced Wireless Re</Text>
</ProgramReference>
<ProgramReference>
<Code>8585</Code>
<Text>NSF/Intel Partnership Projects</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~560000</FUND_OBLG>
<FUND_OBLG>2022~49599</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-06eda04d-7fff-7744-18fc-576ef9aa4700"> </span></p>  <p dir="ltr"><span>From 2020 to 2024, this project aimed to develop a reinforcement-learning-based wireless network management system capable of dynamically updating network configurations to detect, diagnose, and resolve events contributing to quality of experience (QoE) degradation.</span></p>  <p dir="ltr"><span>In the first year, the project supported the creation of a programmable data collection infrastructure that simplified the process of gathering network data, including both endogenously generated data and passive telemetry, from a production campus network for various networking learning problems. It also enabled the development of novel network telemetry systems, such as DynamiQ and OpTel, which effectively assessed dynamic network states at scale. Additionally, the project advanced new offline reinforcement learning algorithms capable of leveraging existing passively collected data.</span></p>  <p dir="ltr"><span>In the second year, the project facilitated progress in QoE inference algorithms for video streaming and video conferencing applications. It also contributed to the development of a novel model explainability tool called Trustee, which identified underspecification issues such as learning shortcuts and spurious correlations affecting the generalizability of machine learning models. The work on Trustee received the Best Paper Honorable Mention at ACM CCS 2023 and the Applied Networking Research Prize (ANRP) from the Internet Research Task Force. The year also saw further fundamental contributions to offline reinforcement learning algorithms.</span></p>  <p dir="ltr"><span>During the third year, the project enabled the development and public release of the data collection infrastructure PINOT and the flexible data collection platform netUnicorn. It also supported the creation of Panakos, a novel telemetry system capable of extracting feature distributions, such as quantile queries, at scale. Significant theoretical advancements were made in offline reinforcement learning with nonlinear function approximations and robustness against model misspecification in online exploration for basic settings.</span></p>  <p dir="ltr"><span>In the final year, the project combined its foundational contributions in data collection, network telemetry systems, and offline reinforcement learning algorithms to address QoE optimization problems in networking through NetAIGym, achieving the core goal of the multi-year effort.</span></p>  <p dir="ltr"><span>More than 25 students, most of whom were undergraduates, participated in the project, gaining hands-on experience in essential research methodologies. These included developing complex packet-processing and data analytics systems, analyzing large-scale datasets, and employing diverse data-gathering and measurement techniques.</span></p>  <p dir="ltr"><span>The project&rsquo;s contributions extend broadly to other disciplines. The artifacts developed, such as PINOT, Trustee, and netUnicorn, simplify the process of collecting high-quality training data and are valuable for a wide range of networking problems, particularly in network security. Similarly, the advancements in offline reinforcement learning algorithms have applications beyond the QoE optimization problems explored in this project.</span></p>  <p dir="ltr"><span>Findings from this project are already influencing decision-making in production networks. For instance, the analysis of QoE for YouTube sessions enabled ViaSat operators to refine traffic-shaping policies for satellite network users. The results also highlighted that most QoE degradation events occur within the first minute of a session, enabling operators to prioritize monitoring during this critical period.</span></p>  <p dir="ltr"><span>Overall, this project has made fundamental contributions to simplifying fine-grained network data collection at scale for various learning problems, improving the analysis of model decision-making, and advancing offline data-driven RL algorithms. The publications, artifacts, and outreach activities have significantly impacted the academic field and laid a foundation for further advancements in optimizing QoE in wireless networks. The research findings have been published in top-tier conferences (e.g., USENIX NSDI, ACM CCS, NeurIPS, ICML, etc.), with one effort earning recognition through the Best Paper Award and the Applied Networking Research Prize.</span></p>  <p>&nbsp;</p><br> <p>  Last Modified: 12/09/2024<br> Modified by: Arpit&nbsp;Gupta</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[       From 2020 to 2024, this project aimed to develop a reinforcement-learning-based wireless network management system capable of dynamically updating network configurations to detect, diagnose, and resolve events contributing to quality of experience (QoE) degradation.    In the first year, the project supported the creation of a programmable data collection infrastructure that simplified the process of gathering network data, including both endogenously generated data and passive telemetry, from a production campus network for various networking learning problems. It also enabled the development of novel network telemetry systems, such as DynamiQ and OpTel, which effectively assessed dynamic network states at scale. Additionally, the project advanced new offline reinforcement learning algorithms capable of leveraging existing passively collected data.    In the second year, the project facilitated progress in QoE inference algorithms for video streaming and video conferencing applications. It also contributed to the development of a novel model explainability tool called Trustee, which identified underspecification issues such as learning shortcuts and spurious correlations affecting the generalizability of machine learning models. The work on Trustee received the Best Paper Honorable Mention at ACM CCS 2023 and the Applied Networking Research Prize (ANRP) from the Internet Research Task Force. The year also saw further fundamental contributions to offline reinforcement learning algorithms.    During the third year, the project enabled the development and public release of the data collection infrastructure PINOT and the flexible data collection platform netUnicorn. It also supported the creation of Panakos, a novel telemetry system capable of extracting feature distributions, such as quantile queries, at scale. Significant theoretical advancements were made in offline reinforcement learning with nonlinear function approximations and robustness against model misspecification in online exploration for basic settings.    In the final year, the project combined its foundational contributions in data collection, network telemetry systems, and offline reinforcement learning algorithms to address QoE optimization problems in networking through NetAIGym, achieving the core goal of the multi-year effort.    More than 25 students, most of whom were undergraduates, participated in the project, gaining hands-on experience in essential research methodologies. These included developing complex packet-processing and data analytics systems, analyzing large-scale datasets, and employing diverse data-gathering and measurement techniques.    The projects contributions extend broadly to other disciplines. The artifacts developed, such as PINOT, Trustee, and netUnicorn, simplify the process of collecting high-quality training data and are valuable for a wide range of networking problems, particularly in network security. Similarly, the advancements in offline reinforcement learning algorithms have applications beyond the QoE optimization problems explored in this project.    Findings from this project are already influencing decision-making in production networks. For instance, the analysis of QoE for YouTube sessions enabled ViaSat operators to refine traffic-shaping policies for satellite network users. The results also highlighted that most QoE degradation events occur within the first minute of a session, enabling operators to prioritize monitoring during this critical period.    Overall, this project has made fundamental contributions to simplifying fine-grained network data collection at scale for various learning problems, improving the analysis of model decision-making, and advancing offline data-driven RL algorithms. The publications, artifacts, and outreach activities have significantly impacted the academic field and laid a foundation for further advancements in optimizing QoE in wireless networks. The research findings have been published in top-tier conferences (e.g., USENIX NSDI, ACM CCS, NeurIPS, ICML, etc.), with one effort earning recognition through the Best Paper Award and the Applied Networking Research Prize.         Last Modified: 12/09/2024       Submitted by: ArpitGupta]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
