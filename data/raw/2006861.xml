<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[III: Small: Collaborative Research: Demystifying Deep Learning on Graphs: From Basic Operations to Applications]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>231268.00</AwardTotalIntnAmount>
<AwardAmount>263268</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hector Munoz-Avila</SignBlockName>
<PO_EMAI>hmunoz@nsf.gov</PO_EMAI>
<PO_PHON>7032924481</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Graphs are ubiquitous in myriad high-impact domains, e.g., social media platforms, collaboration networks, biological networks, and critical infrastructure systems. Recent years have witnessed a surge of research interests in developing deep learning algorithms (in particular graph convolution networks - GCNs) for graph data. By stacking multiple layers of neural network primitives, GCNs learn high-level feature representations and address graph-related applications in an end-to-end manner, achieving superior performance in various learning tasks. In particular, the graph convolution and graph pooling operations are considered as fundamental building blocks of GCNs. However, a vast majority of existing graph convolution and graph pooling operations are simple extensions of the corresponding operations from convolution neural networks. Therefore, they are insufficient to tackle the fundamental challenges brought by real-world graphs and advance high-impact graph mining applications. The primary goal of this project is to develop novel operations to improve the essential building blocks of deep learning algorithms for graphs, propelling the state-of-the-art graph mining and deep learning research to a new frontier and advancing graph-related applications from different disciplines.&lt;br/&gt;&lt;br/&gt;This project proposes a class of novel graph convolution and pooling operations that can faithfully characterize the properties of real-world graphs from different perspectives, and build more tailored and powerful deep architectures in handling high-impact graph applications from different domains. First, it develops a family of trainable graph convolution operations that can integrate properties of real-world graphs from different aspects at the feature-level, edge-level, and node-level. Second, it investigates the problem of graph pooling to support graph-level analytical tasks and develops novel topology-aware graph pooling operations based on node sampling and node clustering. Third, it assesses the impact of proposed graph convolution and graph pooling operations by building more powerful and customized deep learning architectures for various common graph applications, such as graph anomaly detection and graph alignment. This project will be tightly integrated with newly developed undergraduate and graduate courses. The results and findings of this project will be disseminated through public datasets, open-source software repositories, journal and conference publications, special-purpose workshops or tutorials, as well as education and outreach activities.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/17/2020</MinAmdLetterDate>
<MaxAmdLetterDate>02/14/2024</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2006861</AwardID>
<Investigator>
<FirstName>Shuiwang</FirstName>
<LastName>Ji</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shuiwang Ji</PI_FULL_NAME>
<EmailAddress><![CDATA[sji@tamu.edu]]></EmailAddress>
<NSF_ID>000572148</NSF_ID>
<StartDate>08/17/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Texas A&M Engineering Experiment Station]]></Name>
<CityName>COLLEGE STATION</CityName>
<ZipCode>778433124</ZipCode>
<PhoneNumber>9798626777</PhoneNumber>
<StreetAddress><![CDATA[3124 TAMU]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>QD1MX6N5YTN4</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>TEXAS A&amp;M ENGINEERING EXPERIMENT STATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>QD1MX6N5YTN4</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas A&M Engineering Experiment Station]]></Name>
<CityName>College Station</CityName>
<StateCode>TX</StateCode>
<ZipCode>778433112</ZipCode>
<StreetAddress><![CDATA[Room 301 H.R. Bright Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>736400</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002425DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002324DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~231268</FUND_OBLG>
<FUND_OBLG>2023~16000</FUND_OBLG>
<FUND_OBLG>2024~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The primary aim of this project was to develop novel computational operations that process graph structured data and employ these operations in new applications. Through our explorations, this project has resulted in multiple novel operations to improve the essential building blocks of deep learning algorithms for graphs, extending the state-of-the-art graph mining and deep learning research to a new frontier, as well as advancing graph-related applications from different disciplines. We developed (1) Topology-Aware Graph Pooling Networks that performing graph pooling operation while considering graph topology, (2) ProNet that learn complete protein representations, (3) MatFormer that learn representations for crystal materials, (4) Graphair that learn fair graph representations, (5) S-Mixup that performs soft graph mixup, (6) G-FNO that extends Fourier neural operator to be symmetric to group operations, (7) QHNet that learns Hamiltonian matrices from data in quantum mechanics, (8) QH9 which is a density functional theory calculated datasets of Hamiltonian matrices, (9) LECI that learns label and environment causal independence for Graph Out-of-Distribution Generalization, (10) G-Splice that extrapolate graph data, (11) SyMat that generates crystal materials by making use of symmetries, (12) ATTA that performs active test time adaptation, and (15) MFA that preserves equivariance while minimizing frame averaging. We released an open-source graph neural network library DIG (https://github.com/divelab/DIG), which has 950,000+ visitors, 36,000+ installations, and 1,900+ stars within 3 years, and is becoming a robust and dominant ecosystem for GNN research. We delivered a tutorial to the KDD conference on graphs and DIG in 2022. This project involves the training of more than 10 graduate students and undergraduate students. One of the undergraduate students has published a paper at International Conference on Learning Representations as the primary author.</p> <p>&nbsp;</p><br> <p>  Last Modified: 10/25/2024<br> Modified by: Shuiwang&nbsp;Ji</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  The primary aim of this project was to develop novel computational operations that process graph structured data and employ these operations in new applications. Through our explorations, this project has resulted in multiple novel operations to improve the essential building blocks of deep learning algorithms for graphs, extending the state-of-the-art graph mining and deep learning research to a new frontier, as well as advancing graph-related applications from different disciplines. We developed (1) Topology-Aware Graph Pooling Networks that performing graph pooling operation while considering graph topology, (2) ProNet that learn complete protein representations, (3) MatFormer that learn representations for crystal materials, (4) Graphair that learn fair graph representations, (5) S-Mixup that performs soft graph mixup, (6) G-FNO that extends Fourier neural operator to be symmetric to group operations, (7) QHNet that learns Hamiltonian matrices from data in quantum mechanics, (8) QH9 which is a density functional theory calculated datasets of Hamiltonian matrices, (9) LECI that learns label and environment causal independence for Graph Out-of-Distribution Generalization, (10) G-Splice that extrapolate graph data, (11) SyMat that generates crystal materials by making use of symmetries, (12) ATTA that performs active test time adaptation, and (15) MFA that preserves equivariance while minimizing frame averaging. We released an open-source graph neural network library DIG (https://github.com/divelab/DIG), which has 950,000+ visitors, 36,000+ installations, and 1,900+ stars within 3 years, and is becoming a robust and dominant ecosystem for GNN research. We delivered a tutorial to the KDD conference on graphs and DIG in 2022. This project involves the training of more than 10 graduate students and undergraduate students. One of the undergraduate students has published a paper at International Conference on Learning Representations as the primary author.        Last Modified: 10/25/2024       Submitted by: ShuiwangJi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
