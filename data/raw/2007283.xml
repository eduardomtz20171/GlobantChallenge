<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CHS: Small: Inverse Methods for Computer Graphics Material Appearance Design]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>498941.00</AwardTotalIntnAmount>
<AwardAmount>498941</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Material appearance is a critical feature of visual design systems in the service of a wide range of industrial needs, from creating augmented/virtual reality (AR/VR) training environments to designing physical products to specifying the appearance of characters and objects in film and games.  Visual accuracy is needed for reliable training, and intuitive tools are needed to minimize the time required to bring new systems online.  But while design of the geometry of physical products using computational tools is well-established, an unresolved problem is that the appearance of objects shown in computer design systems cannot reliably be matched in physical production.  This project will develop tools for appearance design that create accurate simulations and are easy to use.  Project outcomes will have broad impact, by enabling systems to accelerate job training, by making design for manufacture efficient, and by expanding access to production tools.&lt;br/&gt;&lt;br/&gt;This project will study appearance space to create a new type of material appearance design system.  But studying the full range of material appearance is a grand challenge, so rather than attempting to develop a general theory, appearance space will be studied in three contexts: the space of particular material classes; the space of procedural models encoded as node graphs; and the space of physically realizable bi-scale materials.  In the context of material classes, image examples of classes of materials (e.g., grass, shiny metals, silk fabric) will be gathered and classified by unsupervised learning techniques to discover the structure of each class and the overlap in appearance classifications.  In the context of node graphs used for appearance design, existing graphs for material classes will be collected to find types and structures to drive the design of an automatic system for node graph generation.  And in the context of bi-scale material appearance, classes of meso-scale geometries and micro-scale variations will be studied to characterize the range of appearance they can produce.  The three studies will be brought together in a system that takes examples of distant and close appearance, along with additional user-supplied class qualifiers, and creates new node types and node graph structures to produces a tunable model for the user to edit as needed.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/21/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/15/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2007283</AwardID>
<Investigator>
<FirstName>Julie</FirstName>
<LastName>Dorsey</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Julie Dorsey</PI_FULL_NAME>
<EmailAddress><![CDATA[dorsey@cs.yale.edu]]></EmailAddress>
<NSF_ID>000117724</NSF_ID>
<StartDate>08/21/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Holly</FirstName>
<LastName>Rushmeier</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Holly Rushmeier</PI_FULL_NAME>
<EmailAddress><![CDATA[rushmeier@cs.yale.edu]]></EmailAddress>
<NSF_ID>000179012</NSF_ID>
<StartDate>08/21/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Yale University]]></Name>
<CityName>NEW HAVEN</CityName>
<ZipCode>065113572</ZipCode>
<PhoneNumber>2037854689</PhoneNumber>
<StreetAddress><![CDATA[150 MUNSON ST]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT03</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>FL6GV84CKN57</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>YALE UNIV</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>FL6GV84CKN57</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Yale University]]></Name>
<CityName>New Haven</CityName>
<StateCode>CT</StateCode>
<ZipCode>065208285</ZipCode>
<StreetAddress><![CDATA[AK Watson Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>736700</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~498941</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Designing material appearance is a critical task in creating content for film, games, and VR/AR training systems. It is also an essential component in the design of new physical objects or structures. In the past software systems for material design have had steep learning curves requiring substantial technical expertise, resulting in lengthy design cycles, and limiting the range of people who could successfully use the systems. The outcomes of this project were systems that make use of advances in machine learning to create design systems that take as input natural input such as images and text and produce numerical material appearance descriptions that can be easily tuned by adjusting a small number of parameters. The numerical material appearance descriptions can then be applied to shapes to produce computer generated images depicting realistic scenes. The key innovations behind the new systems were designing appropriate machine learning architectures and training data sets that could invert the natural image and text input and invert the input to a numerical material description. The systems developed work for various classes of materials.</p> <p>&nbsp;</p> <p>The first problem area considered was the design of bi-scale materials, which are materials that have different appearance features depending on the scale they are viewed at. An example of a class of bi-scale materials are woven fabrics where the individual threads are visible on close view, but which look like a smooth surface from a distance. The system developed requires the user only to specify the class of small-scale geometry of the material (i.e. the woven thread pattern) and reflectance of the material viewed at a distance, and a specification of a physically manufacturable material is produced. The process of developing this system also involved work gaining insights into how people perceive material reflectance and the most efficient numerical representation of reflectance for machine learning. The key innovative insight in developing the system was to define a space of material appearance that could be thoroughly sampled, so that the machine learning system could be trained to reliably produce useful results.</p> <p>&nbsp;</p> <p>The second problem area considered was the design of material appearance in the form of mathematical procedures that can be expanded to arbitrary extents and are easily controlled with small numbers of parameters. An example of such a procedure is a brick wall pattern generator that has parameters for the size, placement, and color of bricks that can be used to cover the exterior of a large building model. Because the range of possible appearance materials have is enormous, and different simple&nbsp; input prompts are possible, a series of methods focused on different applications were developed.</p> <p>&nbsp;</p> <p>One system that was developed as the user to specify a material class from commonly used materials in architectural scenes (brick, stucco, grass, and shingles) and an image exemplar to define the material. Because the system is&nbsp; based on a machine learning model on an extensive collection of specific materials and related procedural descriptions expressed the system can produce reliable results, again building on the insight that the range of possible appearance must be clearly defined.&nbsp; A second system extended the range of material appearance that could be designed by taking not only an image exemplar but mark-ups from the designer indicating subclasses in the image. For example, the designer makes simple marks for which part of an image is grout and which is tile in designing a tiled material for use in a kitchen. The key insight for this development was that many materials can be defined as a combination of procedures describing the spatial distribution of sub materials. Finally, a third system was developed&nbsp; that accepts both exemplar images and textual descriptions of the material being designed. The key insight allowing text prompts was that the procedures used to describe material appearance can be organized &nbsp;as a linear sequence of words in natural language, and so machine learning tools from natural language generation can be used to generate material descriptions.</p> <p>&nbsp;</p> <p>The broader impact of the systems and ideas developed in this project is that the process of designing material appearance for either virtual applications such as film and games or physical applications such as architectural design was made much simpler and intuitive. The work was done in collaboration with industry teams as well as research groups at other academic institutions. The work was&nbsp;&nbsp; published in the form of paper descriptions and freely available source code. The collaboration and publication of the work facilitates the rapid adoption of the ideas resulting in design tools that increase productivity and are accessible to a wider population.</p> <p>&nbsp;</p> <p>The work conducted with a&nbsp; team of graduate and undergraduate students. The experience of conducting the work in collaboration with other research groups provided them with fundamental skills to begin their careers in computing.</p> <p>&nbsp;</p><br> <p>  Last Modified: 01/15/2024<br> Modified by: Holly&nbsp;Rushmeier</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Designing material appearance is a critical task in creating content for film, games, and VR/AR training systems. It is also an essential component in the design of new physical objects or structures. In the past software systems for material design have had steep learning curves requiring substantial technical expertise, resulting in lengthy design cycles, and limiting the range of people who could successfully use the systems. The outcomes of this project were systems that make use of advances in machine learning to create design systems that take as input natural input such as images and text and produce numerical material appearance descriptions that can be easily tuned by adjusting a small number of parameters. The numerical material appearance descriptions can then be applied to shapes to produce computer generated images depicting realistic scenes. The key innovations behind the new systems were designing appropriate machine learning architectures and training data sets that could invert the natural image and text input and invert the input to a numerical material description. The systems developed work for various classes of materials.      The first problem area considered was the design of bi-scale materials, which are materials that have different appearance features depending on the scale they are viewed at. An example of a class of bi-scale materials are woven fabrics where the individual threads are visible on close view, but which look like a smooth surface from a distance. The system developed requires the user only to specify the class of small-scale geometry of the material (i.e. the woven thread pattern) and reflectance of the material viewed at a distance, and a specification of a physically manufacturable material is produced. The process of developing this system also involved work gaining insights into how people perceive material reflectance and the most efficient numerical representation of reflectance for machine learning. The key innovative insight in developing the system was to define a space of material appearance that could be thoroughly sampled, so that the machine learning system could be trained to reliably produce useful results.      The second problem area considered was the design of material appearance in the form of mathematical procedures that can be expanded to arbitrary extents and are easily controlled with small numbers of parameters. An example of such a procedure is a brick wall pattern generator that has parameters for the size, placement, and color of bricks that can be used to cover the exterior of a large building model. Because the range of possible appearance materials have is enormous, and different simple input prompts are possible, a series of methods focused on different applications were developed.      One system that was developed as the user to specify a material class from commonly used materials in architectural scenes (brick, stucco, grass, and shingles) and an image exemplar to define the material. Because the system is based on a machine learning model on an extensive collection of specific materials and related procedural descriptions expressed the system can produce reliable results, again building on the insight that the range of possible appearance must be clearly defined. A second system extended the range of material appearance that could be designed by taking not only an image exemplar but mark-ups from the designer indicating subclasses in the image. For example, the designer makes simple marks for which part of an image is grout and which is tile in designing a tiled material for use in a kitchen. The key insight for this development was that many materials can be defined as a combination of procedures describing the spatial distribution of sub materials. Finally, a third system was developed that accepts both exemplar images and textual descriptions of the material being designed. The key insight allowing text prompts was that the procedures used to describe material appearance can be organized as a linear sequence of words in natural language, and so machine learning tools from natural language generation can be used to generate material descriptions.      The broader impact of the systems and ideas developed in this project is that the process of designing material appearance for either virtual applications such as film and games or physical applications such as architectural design was made much simpler and intuitive. The work was done in collaboration with industry teams as well as research groups at other academic institutions. The work was published in the form of paper descriptions and freely available source code. The collaboration and publication of the work facilitates the rapid adoption of the ideas resulting in design tools that increase productivity and are accessible to a wider population.      The work conducted with a team of graduate and undergraduate students. The experience of conducting the work in collaboration with other research groups provided them with fundamental skills to begin their careers in computing.        Last Modified: 01/15/2024       Submitted by: HollyRushmeier]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
