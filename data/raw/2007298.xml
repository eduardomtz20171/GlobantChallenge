<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[SHF:Small:Privacy Impact and Risk Assessment at Design-Time]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>498221.00</AwardTotalIntnAmount>
<AwardAmount>524221</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
<PO_EMAI>sgreensp@nsf.gov</PO_EMAI>
<PO_PHON>7032927841</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Verifying that web and mobile applications will protect user privacy requires knowledge about what kinds of data and data practices are sensitive to users. Privacy impact assessments are standardized procedures that companies and government agencies use to identify what personal information is collected, used, and for what purpose, and shared with whom, as well as, what steps are taken to protect that information. Conducting privacy impact assessments on applications is time consuming, because evaluators often have limited knowledge of the software’s behavior, and the assessments are often done after the software has been constructed, which is costly. Because developers are under pressure to continuously release new application versions, they have little time for extensive documentation about their data practices. Today, the status quo in documenting privacy is the privacy policy, which regulators increasingly check for data practice misrepresentations during the application’s lifetime. This project seeks to develop methods and tools to automatically and quickly conduct privacy impact assessments from software artifacts, called user stories, that are easier for developers to produce. Based on a risk assessment informed by which data practices are most sensitive to users, developers can prioritize where best to introduce privacy controls that users want. Furthermore, by conducting risk assessments from user stories, regulators and developers would have greater assurance that assessments accurately reflect current app behavior. Finally, these assessments save developer time, because a change to a user story could trigger an automatic re-assessment that alerts the developer to changes in privacy risk. This research is transformative because it allows software developers to respond to changes in privacy risk during design time, when important safeguards can be introduced, as opposed to waiting for lengthier impact assessments that are harder to integrate after the software has been constructed.&lt;br/&gt;&lt;br/&gt;The project investigates the symbolic and statistical relationships between agile requirements, privacy risk and privacy policies. The research explores strategies for scoring user stories for privacy risk and prioritizing which stories are most important to user privacy comprehension. The components of the solution will be investigated as follows: (1) corpora of user stories and privacy policies expressed in natural language will be acquired and annotated using coding theory; (2) semantic frames and an ontology expressed in Description Logic will be extracted from the corpora using entity and relation extraction; and (3) the risk scores will be collected using privacy risk surveys that measure how users perceive privacy risk under different scenarios derived from user stories and mitigations. A key obstacle to effectively scoring risk is the inherent presence of ambiguity and vagueness in natural language. The semantic frames and ontology will be used to encode and resolve ambiguity and vagueness in the scenarios. Furthermore, the survey results will be used to model changes in risk due to selected mitigations, thus, developers will be able to explore the local design space around a specific user story and available mitigation choices.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/29/2020</MinAmdLetterDate>
<MaxAmdLetterDate>04/18/2024</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2007298</AwardID>
<Investigator>
<FirstName>Travis</FirstName>
<LastName>Breaux</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Travis Breaux</PI_FULL_NAME>
<EmailAddress><![CDATA[breaux@cs.cmu.edu]]></EmailAddress>
<NSF_ID>000572505</NSF_ID>
<StartDate>06/29/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress><![CDATA[5000 FORBES AVE]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA12</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>U3NKNFLNQ613</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>U3NKNFLNQ613</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>779800</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramElement>
<Code>806000</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7944</Code>
<Text>SOFTWARE ENG &amp; FORMAL METHODS</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002425DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~498221</FUND_OBLG>
<FUND_OBLG>2022~16000</FUND_OBLG>
<FUND_OBLG>2024~10000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><br />Mobile and web applications provide users with services to solve everyday problems. Increasingly, these applications collect personal information to personalize these services to individual user needs. Because privacy is personal and not every user perceives the same level of privacy risk when sharing their personal information, developers need ways to elicit privacy requirements from users before or during design time. This project investigated new ways to collect privacy requirements directly from users by inviting users to describe their experiences in using mobile and web apps. By collecting user perceptions of privacy risk, we could train a machine learning model to predict which information types were high and low risk. This information could then be shared with developers to help them spot privacy hotspots in their application design. In addition, we conduct research to identify ways that software could increase the level of personalization to offer a better fit for user needs. This study revealed gaps in modern software applications where user needs are unaddressed, and where addressing those needs require collecting deeply personal information. This study raises awareness for new ways to develop better software while also identifies a greater need to adopt some of the methods and tools produced by this research. The research resulted in tools to conduct this elicitation exercise and collect the data that developers need.</p><br> <p>  Last Modified: 12/20/2024<br> Modified by: Travis&nbsp;Breaux</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Mobile and web applications provide users with services to solve everyday problems. Increasingly, these applications collect personal information to personalize these services to individual user needs. Because privacy is personal and not every user perceives the same level of privacy risk when sharing their personal information, developers need ways to elicit privacy requirements from users before or during design time. This project investigated new ways to collect privacy requirements directly from users by inviting users to describe their experiences in using mobile and web apps. By collecting user perceptions of privacy risk, we could train a machine learning model to predict which information types were high and low risk. This information could then be shared with developers to help them spot privacy hotspots in their application design. In addition, we conduct research to identify ways that software could increase the level of personalization to offer a better fit for user needs. This study revealed gaps in modern software applications where user needs are unaddressed, and where addressing those needs require collecting deeply personal information. This study raises awareness for new ways to develop better software while also identifies a greater need to adopt some of the methods and tools produced by this research. The research resulted in tools to conduct this elicitation exercise and collect the data that developers need.     Last Modified: 12/20/2024       Submitted by: TravisBreaux]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
