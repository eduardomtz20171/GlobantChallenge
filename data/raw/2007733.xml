<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CNS Core: Small: Caching with Delayed Hits]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>499998.00</AwardTotalIntnAmount>
<AwardAmount>515998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Caches are responsible for storing data close to where computer systems access them in order to make things faster.  For example, when a user accesses a website, the web browser first checks the cache to see if the webpage files are already there; if not, the cache goes to the website servers, which takes longer.  Unfortunately, caches are small and don’t have room to store everything.  In order to make systems faster, this project’s goal is to decide what to store in the cache while accounting for "delayed hits", which occur when multiple requests happen for the same data back-to-back.&lt;br/&gt;&lt;br/&gt;This project will explore the impact of delayed hits on cache performance. Delayed hits occur when a request "misses" in the cache, and a second request occurs for the same object before the first request has returned from the backing store. The second hit does not have equal latency to a true "hit" nor a true "miss". Because caches assume that requests result in either a hit or a miss, caches do not achieve the best possible latency. This project will explore new caching algorithms to achieve better latency by taking delayed hits into account.&lt;br/&gt;&lt;br/&gt;The technical impact of this project will be to improve latencies for a broad range of computer systems that rely on caches, from key-value stores in data centers to web caches.  Systems with very long latencies will benefit the most, leading to the hypothesis that one will see strong benefits for web caches in Internet-underserved regions which may be hundreds of miles from their nearest data center.  This project will also impact education and broaden participation in computing by including undergraduate researchers in the research process.&lt;br/&gt;&lt;br/&gt;All simulators, scripts, and analysis resulting from this work will be uploaded to public repositories (http://www.github.com/cmu-snap) where they may be accessed by the public indefinitely.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/08/2020</MinAmdLetterDate>
<MaxAmdLetterDate>05/19/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2007733</AwardID>
<Investigator>
<FirstName>Justine</FirstName>
<LastName>Sherry</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Justine Sherry</PI_FULL_NAME>
<EmailAddress><![CDATA[justines@andrew.cmu.edu]]></EmailAddress>
<NSF_ID>000728919</NSF_ID>
<StartDate>07/08/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Weina</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Weina Wang</PI_FULL_NAME>
<EmailAddress><![CDATA[weinaw@cs.cmu.edu]]></EmailAddress>
<NSF_ID>000800768</NSF_ID>
<StartDate>07/08/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress><![CDATA[5000 FORBES AVE]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA12</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>U3NKNFLNQ613</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>U3NKNFLNQ613</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>171400</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>735400</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2020~499998</FUND_OBLG>
<FUND_OBLG>2021~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p dir="ltr"><span>Caches are computer systems which store data closer to users and clients that want to access it. By keeping data closer to users, caches make systems such as web sites and computer processors faster. However, caches cannot store every piece of data users want to access because they have a limited amount of storage space. Hence, researchers have invested significant study into&nbsp;</span><span>caching algorithms</span><span>&nbsp;which determine which data to keep in the cache, and which data to store elsewhere. Typically, researchers study caching algorithms by focusing on &ldquo;hit rates&rdquo; (how many requests to the cache result in an access to an object that&nbsp;</span><span>is</span><span>&nbsp;in the cache) and &ldquo;miss rates&rdquo; (how many requests result in an access to the object which&nbsp;</span><span>is not</span><span>&nbsp;in the cache, and hence must be requested from further away).&nbsp;</span></p> <p>&nbsp;</p> <p dir="ltr"><span>In this study, we explored a surprisingly under-analyzed aspect of caching. What happens when a request for an object that is&nbsp;</span><span>not</span><span>&nbsp;in the cache occurs, and then a request for the&nbsp;</span><span>same object</span><span>&nbsp;comes shortly thereafter? This second request does not have to wait as long as a true &ldquo;miss&rdquo; for the object, since the object is already on its way to the cache. But, it is not as fast as a hit because the object is not in the cache, yet, when the request occurs. We call these &ldquo;in between&rdquo; outcomes&nbsp;</span><span>delayed hits.</span><span>&nbsp;</span></p> <p>&nbsp;</p> <p dir="ltr"><span>Our key results included new caching algorithms that are aware of delayed hits, which are able to access data 12-40% faster than traditional caching algorithms. However, in the context of &ldquo;hierarchical&rdquo; caches (in which many caches are used together) our algorithms provided little improvement based on the state of the art. We also explored fundamental limits of perfect caching, and explored new mathematical techniques such as Palm Calculus which improved our understanding and analysis of cache performance.&nbsp;</span></p> <p>&nbsp;</p> <p dir="ltr"><span>Our research promoted national objectives of advancing national technological competitiveness by improving our understanding of caching, a fundamental technology which underlies much of the American tech industry. The project also cultivated an equitable STEM education, engagement, and workforce ecosystem by including trainees in the research project, including PhD students, master&rsquo;s students, and bachelor&rsquo;s students from a range of American institutions and backgrounds.</span></p> <p>&nbsp;</p><br> <p>  Last Modified: 01/29/2024<br> Modified by: Justine&nbsp;Sherry</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Caches are computer systems which store data closer to users and clients that want to access it. By keeping data closer to users, caches make systems such as web sites and computer processors faster. However, caches cannot store every piece of data users want to access because they have a limited amount of storage space. Hence, researchers have invested significant study intocaching algorithmswhich determine which data to keep in the cache, and which data to store elsewhere. Typically, researchers study caching algorithms by focusing on hit rates (how many requests to the cache result in an access to an object thatisin the cache) and miss rates (how many requests result in an access to the object whichis notin the cache, and hence must be requested from further away).      In this study, we explored a surprisingly under-analyzed aspect of caching. What happens when a request for an object that isnotin the cache occurs, and then a request for thesame objectcomes shortly thereafter? This second request does not have to wait as long as a true miss for the object, since the object is already on its way to the cache. But, it is not as fast as a hit because the object is not in the cache, yet, when the request occurs. We call these in between outcomesdelayed hits.      Our key results included new caching algorithms that are aware of delayed hits, which are able to access data 12-40% faster than traditional caching algorithms. However, in the context of hierarchical caches (in which many caches are used together) our algorithms provided little improvement based on the state of the art. We also explored fundamental limits of perfect caching, and explored new mathematical techniques such as Palm Calculus which improved our understanding and analysis of cache performance.      Our research promoted national objectives of advancing national technological competitiveness by improving our understanding of caching, a fundamental technology which underlies much of the American tech industry. The project also cultivated an equitable STEM education, engagement, and workforce ecosystem by including trainees in the research project, including PhD students, masters students, and bachelors students from a range of American institutions and backgrounds.        Last Modified: 01/29/2024       Submitted by: JustineSherry]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
