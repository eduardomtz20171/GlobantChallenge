<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[EXP: Augmenting a Teachable Robot with Adaptive Cognitive and Social Support]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/19/2019</AwardEffectiveDate>
<AwardExpirationDate>04/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>417703.00</AwardTotalIntnAmount>
<AwardAmount>336269</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Amy Baylor</SignBlockName>
<PO_EMAI>abaylor@nsf.gov</PO_EMAI>
<PO_PHON>7032925126</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This proposal investigates robotic teachable agents, a type of cyberlearning technology that provides cognitive and affective feedback to support students' learning. The Tangible Activities for Geometry system (TAG) is a robotic teachable agent platform for middle school mathematics and computational thinking. Students physically engage within a projected coordinate space with an interactive teachable robot named Quinn. Students teach Quinn how to solve challenges involving plotting points on a graph, translating points, rotating points, and plotting lines by giving procedural and conditional instructions to Quinn. There appear to be at least two primary advantages to using a robotic learning platform to investigate how to design teachable agents. First, a physical presence, provided by a robotic agent, strengthens users' perceptions of having a social partner that is more than a virtual agent. Second, students receive cognitive benefits from learning through embodied, physical interactions. This research investigates the unique affordances of a teachable robot for supporting students' cognitive and social interactions within a learning environment as it enhances our understanding of how cyberlearning can support STEM learning (mathematics and computational thinking). The study will be conducted in a school system having high percentages of underrepresented minorities who will learn to design features of the robots, exposing them to STEM careers and increasing the likelihood of acceptance and scalability. The investigative team will also disseminate findings and Do-It-Yourself (DIY) instructions for integrating cyberlearning environments and pedagogical approaches.&lt;br/&gt;&lt;br/&gt;This proposal advances an empirical investigation that uses a teachable robot learning environment built with prior NSF support, integrated within the NYU Holodeck, a state-of-the-art immersive collaborative cyberlearning research environment, to improve understanding of how adaptive cognitive and social support can facilitate embodied interactions with teachable agents. This project investigates the teachable agent phenomenon within the context of the Tangible Activities for Geometry system (TAG), a robotic teachable agent platform for middle school mathematics and computational thinking. The project has three phases. First, the research team will explore two factors related to cognitive support: (1) how the teachable agent can give adaptive feedback representative of a learner (questions, self-explanations) rather than a tutor (hints, instructional explanations), and (2) how cognitive prompts can leverage the physical properties of the environment. Second, the team will explore two factors related to social support: (a) how a teachable agent can make adaptive attributions to effort or ability for its success or failure to motivate students, and (b) how the robot can use its embodied presence (physical or tactile) to contribute social information to enhance student learning. Third, to assess the efficacy of the interventions, the project incorporates a study comparing cognitive and social support to a condition with only cognitive support, only social support, and with no support. The project will make substantial contributions toward better understanding how to design and effectively incorporate support, provided by a teachable robot, to adaptively provide cognitive and social support to improve student outcomes. The robot framework will be tested in schools, including high percentages of underrepresented minorities, developing new ways of using technology to learn mathematics and computational thinking.</AbstractNarration>
<MinAmdLetterDate>05/20/2020</MinAmdLetterDate>
<MaxAmdLetterDate>09/25/2023</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2031148</AwardID>
<Investigator>
<FirstName>Winslow</FirstName>
<LastName>Burleson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Winslow Burleson</PI_FULL_NAME>
<EmailAddress><![CDATA[win@arizona.edu]]></EmailAddress>
<NSF_ID>000249639</NSF_ID>
<StartDate>05/20/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>TUCSON</CityName>
<ZipCode>85721</ZipCode>
<PhoneNumber>5206266000</PhoneNumber>
<StreetAddress><![CDATA[845 N PARK AVE RM 538]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>ED44Y3W6P7B9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARIZONA</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>Tucson</CityName>
<StateCode>AZ</StateCode>
<ZipCode>857194824</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>005Y00</Code>
<Text>STEM + Computing (STEM+C) Part</Text>
</ProgramElement>
<ProgramElement>
<Code>802000</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8841</Code>
<Text>Exploration Projects</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0417</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01001819DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002021DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>04001718DB</Code>
<Name><![CDATA[NSF Education & Human Resource]]></Name>
<FUND_SYMB_ID>040106</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2017~304268</FUND_OBLG>
<FUND_OBLG>2018~16000</FUND_OBLG>
<FUND_OBLG>2020~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-ccd6681e-7fff-9efd-0fe6-a25d958e00ce"> </span></p> <p dir="ltr"><span style="text-decoration: underline;"><strong>Project Goals:</strong></span></p> <p dir="ltr"><span>&nbsp;</span><span> Interactive activities can be highly beneficial for learning: Students may construct knowledge when contributing to a group discussion, be guided by a knowledgeable partner, or co-construct knowledge with others. Recent advances in technology have led to the development of pedagogical agents that foster learning through agent-student tutoring, i.e., Intelligent Tutoring Systems. In addition to cognitive gains, exchanges with a virtual tutor have the potential to facilitate social, motivational, and collaborative interactions, which are key to developing a more complex understanding of the material.</span></p> <p dir="ltr"><span>One type of pedagogical agent that has the most potential for addressing holistic learning interactions is the teachable agent. In a teachable agent system, the student plays the role of a peer tutor, iteratively teaching a virtual character about the target domain and in the process refining his/her own understanding. Prior work has demonstrated the cognitive and social benefits of human-human peer tutoring and by extension, to have a student teach an agent. Literature supports that using teachable agents can promote self-reflection and intrinsic motivation about learning. However, it is not fully understood how to design and implement a teachable agent to maximize student learning.</span></p> <p dir="ltr"><span>Existing teachable agents are primarily passive, reactive respondents, and do not replicate the collaborative, physical environment of human peer tutoring. Our first goal is to better understand how cognitive and social interactions between a student and a teachable agent can improve learning outcomes, and integrate these findings into the design. The second goal of our research program is to investigate the unique affordances of a teachable robot to support students&rsquo; cognitive and social interactions with learning environments. Essential to advancing the design of teachable agents, and specifically embodied teachable agents, the third goal is refining learning analytics approaches suitable for analyzing the complex learning that occurs in an embodied environment.</span></p> <p dir="ltr"><span style="text-decoration: underline;"><strong>Project Activities:</strong></span></p> <p dir="ltr"><span>We have created a cohesive platform for robotic-TAG (r-TAG)/Chalk-Talk that integrates various affective sensors and robotic platforms with key elements of the ChalkTalk graphic system and user interface.&nbsp; We have integrated the tangible activities for the geometry robotic platform with the MRI Holodeck and the spatial ChalkTalk graphic system.&nbsp; These combined technologies are integrated using the versatile &ldquo;corelink&rdquo; module to incorporate and expand the interactive authoring and AR/VR capabilities that can be experienced by students in real time. Corelink handles sending, receiving, recording, and replaying data throughout the collocated and distributed holodeck node servers and constituent technologies, providing seamless cross-modality integration that drives real-time interactive Mixed Reality (MR) collaborative experiences.&nbsp;</span></p> <p dir="ltr"><span>Corelink has also enabled us to integrate University of Arizona Sensor Lab sensors into the suite of technologies, thereby expanding the affective and contextual sensing capabilities of the system.&nbsp; We have conducted studies on the feasibility of using these sensors and hardware in conjunction with interactive social and affective robots. The affordances of student interactions with the robot and their use of the ChalkTalk graphic system have been streamlined and tailored to facilitate learning, motivation, social interactions, and social engagement in the context of open-ended individual and small-group problem-solving activities.&nbsp;</span></p> <p dir="ltr"><span>Collectively, these integrated systems provide the foundational infrastructure to integrate signals and experiences across holodeck nodes, users, and technologies. We have also successfully implemented and tested interactive collaborative Holodeck features across several modalities, with low latency, between NYU and UA, as part of the expansion of the NSF MRI Holodeck Project.&nbsp;</span></p> <p dir="ltr"><span>We continued partnerships with the Rio School District and initiated ones in Tucson. We have integrated the findings from these activities into the system and our iterative evaluation to date and continue to develop and conduct empirical studies and prepare publications to disseminate our findings.&nbsp; These studies and infrastructure advancements demonstrate the capacity to extend the </span><span>Teachable Robot with Adaptive Cognitive and Social Support</span><span> systems into classrooms.&nbsp;</span></p> <p dir="ltr"><span style="text-decoration: underline;"><strong>Broader Impacts:&nbsp;</strong></span></p> <p><span id="docs-internal-guid-89d3808f-7fff-efa4-723a-83d2375cb507"> <p dir="ltr">Broader societal impacts from this project is that the rTAG framework and research methodologies can inform and be re-configured to support learning in a broad array of domains. A better understanding of the impact of teachable robots will pave the way for these technologies to be adopted in a manner that leverages principles of learning and contributes to closing achievement gaps. The rTAG robotic infrastructure will also be useful to the advancement of the performing arts within the Holodeck, as it can facilitate the interactions of multiple individuals and robots in dynamic real-time experiences.</p> </span></p><br> <p>  Last Modified: 09/11/2024<br> Modified by: Winslow&nbsp;Burleson</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[      Project Goals:    Interactive activities can be highly beneficial for learning: Students may construct knowledge when contributing to a group discussion, be guided by a knowledgeable partner, or co-construct knowledge with others. Recent advances in technology have led to the development of pedagogical agents that foster learning through agent-student tutoring, i.e., Intelligent Tutoring Systems. In addition to cognitive gains, exchanges with a virtual tutor have the potential to facilitate social, motivational, and collaborative interactions, which are key to developing a more complex understanding of the material.   One type of pedagogical agent that has the most potential for addressing holistic learning interactions is the teachable agent. In a teachable agent system, the student plays the role of a peer tutor, iteratively teaching a virtual character about the target domain and in the process refining his/her own understanding. Prior work has demonstrated the cognitive and social benefits of human-human peer tutoring and by extension, to have a student teach an agent. Literature supports that using teachable agents can promote self-reflection and intrinsic motivation about learning. However, it is not fully understood how to design and implement a teachable agent to maximize student learning.   Existing teachable agents are primarily passive, reactive respondents, and do not replicate the collaborative, physical environment of human peer tutoring. Our first goal is to better understand how cognitive and social interactions between a student and a teachable agent can improve learning outcomes, and integrate these findings into the design. The second goal of our research program is to investigate the unique affordances of a teachable robot to support students cognitive and social interactions with learning environments. Essential to advancing the design of teachable agents, and specifically embodied teachable agents, the third goal is refining learning analytics approaches suitable for analyzing the complex learning that occurs in an embodied environment.   Project Activities:   We have created a cohesive platform for robotic-TAG (r-TAG)/Chalk-Talk that integrates various affective sensors and robotic platforms with key elements of the ChalkTalk graphic system and user interface. We have integrated the tangible activities for the geometry robotic platform with the MRI Holodeck and the spatial ChalkTalk graphic system. These combined technologies are integrated using the versatile corelink module to incorporate and expand the interactive authoring and AR/VR capabilities that can be experienced by students in real time. Corelink handles sending, receiving, recording, and replaying data throughout the collocated and distributed holodeck node servers and constituent technologies, providing seamless cross-modality integration that drives real-time interactive Mixed Reality (MR) collaborative experiences.   Corelink has also enabled us to integrate University of Arizona Sensor Lab sensors into the suite of technologies, thereby expanding the affective and contextual sensing capabilities of the system. We have conducted studies on the feasibility of using these sensors and hardware in conjunction with interactive social and affective robots. The affordances of student interactions with the robot and their use of the ChalkTalk graphic system have been streamlined and tailored to facilitate learning, motivation, social interactions, and social engagement in the context of open-ended individual and small-group problem-solving activities.   Collectively, these integrated systems provide the foundational infrastructure to integrate signals and experiences across holodeck nodes, users, and technologies. We have also successfully implemented and tested interactive collaborative Holodeck features across several modalities, with low latency, between NYU and UA, as part of the expansion of the NSF MRI Holodeck Project.   We continued partnerships with the Rio School District and initiated ones in Tucson. We have integrated the findings from these activities into the system and our iterative evaluation to date and continue to develop and conduct empirical studies and prepare publications to disseminate our findings. These studies and infrastructure advancements demonstrate the capacity to extend the Teachable Robot with Adaptive Cognitive and Social Support systems into classrooms.   Broader Impacts:      Broader societal impacts from this project is that the rTAG framework and research methodologies can inform and be re-configured to support learning in a broad array of domains. A better understanding of the impact of teachable robots will pave the way for these technologies to be adopted in a manner that leverages principles of learning and contributes to closing achievement gaps. The rTAG robotic infrastructure will also be useful to the advancement of the performing arts within the Holodeck, as it can facilitate the interactions of multiple individuals and robots in dynamic real-time experiences.      Last Modified: 09/11/2024       Submitted by: WinslowBurleson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
