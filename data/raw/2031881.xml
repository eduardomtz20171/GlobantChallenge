<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CIF: Small: Mobile Immersive Communication: View Sampling and Rate-Distortion Limits]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>33746.00</AwardTotalIntnAmount>
<AwardAmount>52746</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Free-viewpoint video is an emerging technology for visual communication that creates the sensation of 3D immersion in the remote scene by allowing the user to dynamically switch between arbitrary viewpoints. It has the potential to advance society by enabling virtual human transportation and boost the global economy and quality of life. At present, free-viewpoint video is limited to high-end computing environments and studio-type settings, due to its higher bandwidth and complexity expansion over single-view video. Furthermore, the fundamental questions of viewpoint sampling (camera location) and resource allocation across the captured views are largely unanswered, due to the nascency of the technology, and are addressed using suboptimal heuristic approaches, thus penalizing  system efficiency. These two characteristics would otherwise make free-viewpoint video impractical and preclude its broader deployment, in particular on mobile devices, due to their constrained bandwidth, battery power, and CPU capabilities. However, the latter have become a primary platform for computing and communication needs, anywhere and anytime, a trend that will only accelerate in the future. Thus, it is anticipated that only by enabling ubiquitous and seamless mobile free-viewpoint video may the full potential of immersive communication be achieved. This project seeks to achieve this goal via concerted advances in signal representation, wireless video communication, and user-action modeling that will be integrated holistically.  The advances delivered by this investigation will have broad impact across diverse fields that involve live video communication via multiple viewpoints, including telemedicine, telepresence and telecollaboration, remote monitoring and control, entertainment (3D and free-viewpoint TV), gaming and virtual worlds, people-centric sensing and connected-community applications.&lt;br/&gt;&lt;br/&gt;The project will pursue the following technical thrusts: (i) Characterization of the fundamental trade-offs between viewpoint space sampling, rate allocation, and signal fidelity in immersive mobile communication; (ii) Derivation of the optimal sampling policy, at the view and data-unit levels, in uplink communication; (iii) Design of novel view and rate scalable coding for multi-view broadcast and derivation of the optimal view embedding policy, as a function of the broadcast rate, in downlink communication; (iv) Characterization of the optimal scheduling policy for local ad-hoc communication between mobile clients; and (v) Integration of energy conservation and characterization of the trade-offs between battery lifetime and multi-view application performance.</AbstractNarration>
<MinAmdLetterDate>09/18/2020</MinAmdLetterDate>
<MaxAmdLetterDate>11/14/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2031881</AwardID>
<Investigator>
<FirstName>Jacob</FirstName>
<LastName>Chakareski</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jacob Chakareski</PI_FULL_NAME>
<EmailAddress><![CDATA[jacobcha@njit.edu]]></EmailAddress>
<NSF_ID>000663351</NSF_ID>
<StartDate>09/18/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[New Jersey Institute of Technology]]></Name>
<CityName>NEWARK</CityName>
<ZipCode>071021824</ZipCode>
<PhoneNumber>9735965275</PhoneNumber>
<StreetAddress><![CDATA[323 DR MARTIN LUTHER KING JR BLV]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ10</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>SGBMHQ7VXNH5</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>NEW JERSEY INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[New Jersey Institute of Technology]]></Name>
<CityName>Newark</CityName>
<StateCode>NJ</StateCode>
<ZipCode>071021982</ZipCode>
<StreetAddress><![CDATA[University Heights]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>779700</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramElement>
<Code>915000</Code>
<Text>EPSCoR Co-Funding</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01001718DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01001516DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01001718DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2015~33746</FUND_OBLG>
<FUND_OBLG>2017~19000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Free-viewpoint video (FVV) is a novel technology for visual communication that creates the sensation of 3D immersion in the remote scene by allowing the user to dynamically switch between arbitrary viewpoints. It has the potential to dramatically advance our society by enabling novel applications of remote immersion, inclusive of helping address climate change. Presently, FVV is limited to high-end computing environments and studio-type settings, due to its N-fold bandwidth and complexity expansion over single-view video. Plus, the fundamental questions of viewpoint sampling (camera location) and resource allocation across the captured views have largely remained unanswered, which dramatically penalizes the system efficiency. These two characteristics make FVV highly impractical and preclude its broader deployment, in particular on mobile devices. The project has aimed to enable ubiquitous and seamless mobile FVV via concerted advances in signal representation, wireless video communication, and user-action modeling that are integrated holistically.</p> <p><br />Intellectual merits of the project include: (i) Characterization of the fundamental trade-offs between viewpoint space sampling, rate allocation, and signal fidelity in immersive mobile communication. (ii) Derivation of the optimal sampling policy, at the view and data-unit levels, in uplink communication. (iii) Design of novel view and rate scalable coding for multi-view broadcast and derivation of the optimal view embedding policy, as a function of the broadcast rate, in downlink communication. (iv) Characterization of the optimal scheduling policy for local ad-hoc communication between mobile clients. (v) Integration of energy conservation and characterization of the trade-offs between battery lifetime and multi-view application performance.</p> <p>(the interface to submit this report is very limited and buggy. I hope someone will look into this.)</p><br> <p>  Last Modified: 12/15/2023<br> Modified by: Jacob&nbsp;Chakareski</p></div> <div class="porSideCol" ><div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)          </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2023/2031881/2031881_10392097_1702663003791_ProjectDescription--rgov-214x142.bmp" original="/por/images/Reports/POR/2023/2031881/2031881_10392097_1702663003791_ProjectDescription--rgov-800width.bmp" title="Cloud-assisted mobile immersive communication"><img src="/por/images/Reports/POR/2023/2031881/2031881_10392097_1702663003791_ProjectDescription--rgov-66x44.bmp" alt="Cloud-assisted mobile immersive communication"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Cloud-assisted free-viewpoint multi-client mobile video streaming. Clients receive content from the cloud via a broadcast stream B. Clients upload captured views via dashed connections. Clients cooperate via ad-hoc solid connections.</div> <div class="imageCredit">Jacob Chakareski</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jacob&nbsp;Chakareski <div class="imageTitle">Cloud-assisted mobile immersive communication</div> </div> </li><li> <a href="/por/images/Reports/POR/2023/2031881/2031881_10392097_1697674127906_ProjectDescription--rgov-214x142.bmp" original="/por/images/Reports/POR/2023/2031881/2031881_10392097_1697674127906_ProjectDescription--rgov-800width.bmp" title="Cloud-assisted decentralized free-viewpoint mobile video streaming."><img src="/por/images/Reports/POR/2023/2031881/2031881_10392097_1697674127906_ProjectDescription--rgov-66x44.bmp" alt="Cloud-assisted decentralized free-viewpoint mobile video streaming."></a> <div class="imageCaptionContainer"> <div class="imageCaption">Cloud-assisted FVV streaming.</div> <div class="imageCredit">Jacob Chakareski</div> <div class="imagePermisssions"></div> <div class="imageSubmitted">Jacob&nbsp;Chakareski <div class="imageTitle">Cloud-assisted decentralized free-viewpoint mobile video streaming.</div> </div> </li></ul> </div> </div></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Free-viewpoint video (FVV) is a novel technology for visual communication that creates the sensation of 3D immersion in the remote scene by allowing the user to dynamically switch between arbitrary viewpoints. It has the potential to dramatically advance our society by enabling novel applications of remote immersion, inclusive of helping address climate change. Presently, FVV is limited to high-end computing environments and studio-type settings, due to its N-fold bandwidth and complexity expansion over single-view video. Plus, the fundamental questions of viewpoint sampling (camera location) and resource allocation across the captured views have largely remained unanswered, which dramatically penalizes the system efficiency. These two characteristics make FVV highly impractical and preclude its broader deployment, in particular on mobile devices. The project has aimed to enable ubiquitous and seamless mobile FVV via concerted advances in signal representation, wireless video communication, and user-action modeling that are integrated holistically.    Intellectual merits of the project include: (i) Characterization of the fundamental trade-offs between viewpoint space sampling, rate allocation, and signal fidelity in immersive mobile communication. (ii) Derivation of the optimal sampling policy, at the view and data-unit levels, in uplink communication. (iii) Design of novel view and rate scalable coding for multi-view broadcast and derivation of the optimal view embedding policy, as a function of the broadcast rate, in downlink communication. (iv) Characterization of the optimal scheduling policy for local ad-hoc communication between mobile clients. (v) Integration of energy conservation and characterization of the trade-offs between battery lifetime and multi-view application performance.   (the interface to submit this report is very limited and buggy. I hope someone will look into this.)     Last Modified: 12/15/2023       Submitted by: JacobChakareski]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
