<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[FAI: causal and semi-parametric inference for explanations of disparities and disparity-correcting modeling]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>399923.00</AwardTotalIntnAmount>
<AwardAmount>399923</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Todd Leen</SignBlockName>
<PO_EMAI>tleen@nsf.gov</PO_EMAI>
<PO_PHON>7032927215</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As learning algorithms become ubiquitous in our lives, many have expressed concerns about the potentially harmful biases and disparities that may arise when these algorithms use sensitive features in the data --- such as race, age, gender, or health --- inappropriately.  This project aims to understand and correct for these disparities using causal inference, which aims to use data to quantify cause--effect relationships. Such relationships can be uncovered by trying to predict the change in an effect when a cause variable takes on a different value than one it usually attains. For example, ethnic disparities in health outcomes may arise from different rates of pre-existing comorbidities in different ethnic groups, or from differences in care arising from implicit biases, or from some other mechanisms unmeasured in the data. The indirect effect on health outcome of group-dependent rates of comorbidities can be conceptualized as follows. Measure the health outcomes in patients from ethnic Group A, then use a reliable model to predict outcomes for the same patients with comorbidity rates artificially set to that of ethnic Group B, while leaving everything else the same, and compare the two.  Disparity between the measured and predicted health outcomes point to differing comorbidity rates as the cause. Similarly, a direct effect could be revealed by comparing health outcomes in patients from ethnic Group A with predicted health outcomes in that same group with all variables participating in known indirect mechanisms giving rise to disparities left intact, but the variable indicating ethnicity changed to that for Group B.  Such a direct effect may be viewed as the proportion of the overall effect of ethnicity on the outcome not explained by indirect effects. This project aims to develop methods that use data to predict how such hypothetical comparisons would turn out, use the results to better understand mechanisms of disparities in healthcare, and build predictive models that are aware, and can correct for undesirable mechanisms of disparity.&lt;br/&gt;&lt;br/&gt;In this project, the investigator aims to address conceptual, methodological, and practical gaps in explaining disparities via their causal mechanisms and building models and tools that can correct for mechanisms deemed impermissible. An example of such a mechanism is a direct dependence of a decision or outcome on perceived race or gender.  The investigator will develop methods that can assess the extent to which disparities in outcomes with respect to a sensitive feature can be attributed to distinct causal pathways. To address challenges causal inference faces in complex high-dimensional settings, the investigator will adopt modern semi-parametric methods that are able to use machine learning models while retaining desirable properties of robustness and rapids rates of convergence. In addition, the investigator will develop a novel combination of methods from causal and semi-parametric inference, and constrained optimization to create predictive models and decision support tools that use data efficiently while preventing impermissible mechanisms of disparity from operating, for instance by ensuring that perceived ethnicity has no direct effect on outcomes or decisions made.  The approach will be applied to quantifying disparities and building decision support tools using a complex data set obtained from electronic health records at Johns Hopkins University.  All methods will be implemented in an open-source software package Ananke.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/20/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2040804</AwardID>
<Investigator>
<FirstName>Ilya</FirstName>
<LastName>Shpitser</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ilya Shpitser</PI_FULL_NAME>
<EmailAddress><![CDATA[ilyas@cs.jhu.edu]]></EmailAddress>
<NSF_ID>000727572</NSF_ID>
<StartDate>08/20/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Marc</FirstName>
<LastName>Sussman</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marc S Sussman</PI_FULL_NAME>
<EmailAddress><![CDATA[msussma1@jhmi.edu]]></EmailAddress>
<NSF_ID>000804874</NSF_ID>
<StartDate>08/20/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Glenn</FirstName>
<LastName>Whitman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Glenn Whitman</PI_FULL_NAME>
<EmailAddress><![CDATA[gwhitman@jhmi.edu]]></EmailAddress>
<NSF_ID>000804922</NSF_ID>
<StartDate>08/20/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName>BALTIMORE</CityName>
<ZipCode>212182608</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress><![CDATA[3400 N CHARLES ST]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>FTMTDMBR29C7</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>THE JOHNS HOPKINS UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>GS4PNKTRNKL3</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212182686</ZipCode>
<StreetAddress><![CDATA[1101 E 33rd St,Suite B001]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>114Y00</Code>
<Text>Fairness in Artificial Intelli</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~399923</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1">The purpose of this project was to develop identification and semi-parametric estimation theory for direct, indirect, and path-specific effects used in causal mediation analysis, and address common complications that arise in assessing such effects in real data, including selection bias, measurement error, and missing data.<span>&nbsp; </span>Such effects have previously shown to be important for assessing disparities, and quantifying discrimination.</p>  <p class="p2">&nbsp;</p>  <p class="p1">As part of broader impacts, the project aimed to introduce causal mediation analysis conceptualization of algorithmic fairness into computer science courses at Johns Hopkins University, organize a workshop at the Malone Center for Engineering in Healthcare on disparity quantification and fairness, and organize workshops and tutorials at data science conferences on disparities, fairness, causal mediation, and related topics.</p>  <p class="p2">&nbsp;</p>  <p class="p1">The project outcomes include a number of publications pertaining to topics described above at top peer reviewed conference venues in machine learning and artificial intelligence, and statistics journals, such as Journal of Machine Learning Research (JMLR), Journal of the American Statistical Association (JASA), Conference on Causal Learning and Reasoning (CLEAR), Conference on Uncertainty in Artificial Intelligence (UAI), Conference on Artificial Intelligence and Statistics (AISTATS), International Conference on Machine Learning (ICML), Biometrika, and Annals of Statistics.</p>  <p class="p2">&nbsp;</p>  <p class="p1">In addition, the PI ran a full day course on mediation analysis at the 36th New England Statistics Symposium (NESS-2023), introduced algorithmic fairness and causal mediation into courses at Johns Hopkins, and gave a number of presentations and tutorials on related topics.</p>  <p class="p2">&nbsp;</p>  <p class="p1">Finally, a number of methodological advanced developed in this project have been implemented in the open source causal inference Python package Ananke, developed by the PI and his present and formet students.</p>  <p>&nbsp;</p><br> <p>  Last Modified: 12/26/2024<br> Modified by: Ilya&nbsp;Shpitser</p></div> <div class="porSideCol" ></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  The purpose of this project was to develop identification and semi-parametric estimation theory for direct, indirect, and path-specific effects used in causal mediation analysis, and address common complications that arise in assessing such effects in real data, including selection bias, measurement error, and missing data. Such effects have previously shown to be important for assessing disparities, and quantifying discrimination.        As part of broader impacts, the project aimed to introduce causal mediation analysis conceptualization of algorithmic fairness into computer science courses at Johns Hopkins University, organize a workshop at the Malone Center for Engineering in Healthcare on disparity quantification and fairness, and organize workshops and tutorials at data science conferences on disparities, fairness, causal mediation, and related topics.        The project outcomes include a number of publications pertaining to topics described above at top peer reviewed conference venues in machine learning and artificial intelligence, and statistics journals, such as Journal of Machine Learning Research (JMLR), Journal of the American Statistical Association (JASA), Conference on Causal Learning and Reasoning (CLEAR), Conference on Uncertainty in Artificial Intelligence (UAI), Conference on Artificial Intelligence and Statistics (AISTATS), International Conference on Machine Learning (ICML), Biometrika, and Annals of Statistics.        In addition, the PI ran a full day course on mediation analysis at the 36th New England Statistics Symposium (NESS-2023), introduced algorithmic fairness and causal mediation into courses at Johns Hopkins, and gave a number of presentations and tutorials on related topics.        Finally, a number of methodological advanced developed in this project have been implemented in the open source causal inference Python package Ananke, developed by the PI and his present and formet students.         Last Modified: 12/26/2024       Submitted by: IlyaShpitser]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
